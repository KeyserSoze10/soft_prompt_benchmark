
CondaSystemExit: Exiting.



==> WARNING: A newer version of conda exists. <==
  current version: 4.11.0
  latest version: 4.12.0

Please update conda by running

    $ conda update -n base -c defaults conda


Using the `WAND_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).
[INFO|tokenization_auto.py:334] 2022-04-19 01:27:31,167 >> Could not locate the tokenizer configuration file, will try to use the model config instead.
[INFO|file_utils.py:1664] 2022-04-19 01:27:31,337 >> https://huggingface.co/gpt2-medium/resolve/main/config.json not found in cache or force_download set to True, downloading to /home/ask9126/.cache/huggingface/transformers/tmpdfap4zxl
Downloading:   0%|          | 0.00/718 [00:00<?, ?B/s]Downloading: 100%|██████████| 718/718 [00:00<00:00, 1.24MB/s]
[INFO|file_utils.py:1668] 2022-04-19 01:27:31,472 >> storing https://huggingface.co/gpt2-medium/resolve/main/config.json in cache at /home/ask9126/.cache/huggingface/transformers/3a7a4b7235202f93d14a4a5e8200709184c5b25a29d9cfa6b0ede5166adf0768.cf0ec4a33a38dc96108560e01338af4bd3360dd859385d451c35b41987ae73ff
[INFO|file_utils.py:1676] 2022-04-19 01:27:31,479 >> creating metadata file for /home/ask9126/.cache/huggingface/transformers/3a7a4b7235202f93d14a4a5e8200709184c5b25a29d9cfa6b0ede5166adf0768.cf0ec4a33a38dc96108560e01338af4bd3360dd859385d451c35b41987ae73ff
[INFO|configuration_utils.py:583] 2022-04-19 01:27:31,492 >> loading configuration file https://huggingface.co/gpt2-medium/resolve/main/config.json from cache at /home/ask9126/.cache/huggingface/transformers/3a7a4b7235202f93d14a4a5e8200709184c5b25a29d9cfa6b0ede5166adf0768.cf0ec4a33a38dc96108560e01338af4bd3360dd859385d451c35b41987ae73ff
[INFO|configuration_utils.py:620] 2022-04-19 01:27:31,492 >> Model config GPT2Config {
  "activation_function": "gelu_new",
  "architectures": [
    "GPT2LMHeadModel"
  ],
  "attn_pdrop": 0.1,
  "bos_token_id": 50256,
  "embd_pdrop": 0.1,
  "eos_token_id": 50256,
  "initializer_range": 0.02,
  "layer_norm_epsilon": 1e-05,
  "model_type": "gpt2",
  "n_ctx": 1024,
  "n_embd": 1024,
  "n_head": 16,
  "n_inner": null,
  "n_layer": 24,
  "n_positions": 1024,
  "n_special": 0,
  "predict_special_tokens": true,
  "resid_pdrop": 0.1,
  "scale_attn_weights": true,
  "summary_activation": null,
  "summary_first_dropout": 0.1,
  "summary_proj_to_labels": true,
  "summary_type": "cls_index",
  "summary_use_proj": true,
  "task_specific_params": {
    "text-generation": {
      "do_sample": true,
      "max_length": 50
    }
  },
  "transformers_version": "4.11.3",
  "use_cache": true,
  "vocab_size": 50257
}

[INFO|file_utils.py:1664] 2022-04-19 01:27:31,795 >> https://huggingface.co/gpt2-medium/resolve/main/vocab.json not found in cache or force_download set to True, downloading to /home/ask9126/.cache/huggingface/transformers/tmprz82nrec
Downloading:   0%|          | 0.00/0.99M [00:00<?, ?B/s]Downloading:  77%|███████▋  | 784k/0.99M [00:00<00:00, 7.42MB/s]Downloading: 100%|██████████| 0.99M/0.99M [00:00<00:00, 9.38MB/s]
[INFO|file_utils.py:1668] 2022-04-19 01:27:32,075 >> storing https://huggingface.co/gpt2-medium/resolve/main/vocab.json in cache at /home/ask9126/.cache/huggingface/transformers/fee58641d7a73348d842afaa337d5a7763dad32beff8d9008bb3c3c847749d6b.c7ed1f96aac49e745788faa77ba0a26a392643a50bb388b9c04ff469e555241f
[INFO|file_utils.py:1676] 2022-04-19 01:27:32,080 >> creating metadata file for /home/ask9126/.cache/huggingface/transformers/fee58641d7a73348d842afaa337d5a7763dad32beff8d9008bb3c3c847749d6b.c7ed1f96aac49e745788faa77ba0a26a392643a50bb388b9c04ff469e555241f
[INFO|file_utils.py:1664] 2022-04-19 01:27:32,239 >> https://huggingface.co/gpt2-medium/resolve/main/merges.txt not found in cache or force_download set to True, downloading to /home/ask9126/.cache/huggingface/transformers/tmpynpl1zqv
Downloading:   0%|          | 0.00/446k [00:00<?, ?B/s]Downloading: 100%|██████████| 446k/446k [00:00<00:00, 4.83MB/s]
[INFO|file_utils.py:1668] 2022-04-19 01:27:32,496 >> storing https://huggingface.co/gpt2-medium/resolve/main/merges.txt in cache at /home/ask9126/.cache/huggingface/transformers/23c853a0fcfc12c7d72ad4e922068b6982665b673f6de30b4c5cbe5bd70a2236.5d12962c5ee615a4c803841266e9c3be9a691a924f72d395d3a6c6c81157788b
[INFO|file_utils.py:1676] 2022-04-19 01:27:32,502 >> creating metadata file for /home/ask9126/.cache/huggingface/transformers/23c853a0fcfc12c7d72ad4e922068b6982665b673f6de30b4c5cbe5bd70a2236.5d12962c5ee615a4c803841266e9c3be9a691a924f72d395d3a6c6c81157788b
[INFO|file_utils.py:1664] 2022-04-19 01:27:32,662 >> https://huggingface.co/gpt2-medium/resolve/main/tokenizer.json not found in cache or force_download set to True, downloading to /home/ask9126/.cache/huggingface/transformers/tmpsk_1mkrm
Downloading:   0%|          | 0.00/1.29M [00:00<?, ?B/s]Downloading:  49%|████▉     | 649k/1.29M [00:00<00:00, 6.65MB/s]Downloading: 100%|██████████| 1.29M/1.29M [00:00<00:00, 11.0MB/s]
[INFO|file_utils.py:1668] 2022-04-19 01:27:32,996 >> storing https://huggingface.co/gpt2-medium/resolve/main/tokenizer.json in cache at /home/ask9126/.cache/huggingface/transformers/8e4f9a65085b1b4ae69ffac9a953a44249c9ea1e72e4a7816ee87b70081df038.cf2d0ecb83b6df91b3dbb53f1d1e4c311578bfd3aa0e04934215a49bf9898df0
[INFO|file_utils.py:1676] 2022-04-19 01:27:33,001 >> creating metadata file for /home/ask9126/.cache/huggingface/transformers/8e4f9a65085b1b4ae69ffac9a953a44249c9ea1e72e4a7816ee87b70081df038.cf2d0ecb83b6df91b3dbb53f1d1e4c311578bfd3aa0e04934215a49bf9898df0
[INFO|tokenization_utils_base.py:1741] 2022-04-19 01:27:33,400 >> loading file https://huggingface.co/gpt2-medium/resolve/main/vocab.json from cache at /home/ask9126/.cache/huggingface/transformers/fee58641d7a73348d842afaa337d5a7763dad32beff8d9008bb3c3c847749d6b.c7ed1f96aac49e745788faa77ba0a26a392643a50bb388b9c04ff469e555241f
[INFO|tokenization_utils_base.py:1741] 2022-04-19 01:27:33,400 >> loading file https://huggingface.co/gpt2-medium/resolve/main/merges.txt from cache at /home/ask9126/.cache/huggingface/transformers/23c853a0fcfc12c7d72ad4e922068b6982665b673f6de30b4c5cbe5bd70a2236.5d12962c5ee615a4c803841266e9c3be9a691a924f72d395d3a6c6c81157788b
[INFO|tokenization_utils_base.py:1741] 2022-04-19 01:27:33,400 >> loading file https://huggingface.co/gpt2-medium/resolve/main/tokenizer.json from cache at /home/ask9126/.cache/huggingface/transformers/8e4f9a65085b1b4ae69ffac9a953a44249c9ea1e72e4a7816ee87b70081df038.cf2d0ecb83b6df91b3dbb53f1d1e4c311578bfd3aa0e04934215a49bf9898df0
[INFO|tokenization_utils_base.py:1741] 2022-04-19 01:27:33,400 >> loading file https://huggingface.co/gpt2-medium/resolve/main/added_tokens.json from cache at None
[INFO|tokenization_utils_base.py:1741] 2022-04-19 01:27:33,400 >> loading file https://huggingface.co/gpt2-medium/resolve/main/special_tokens_map.json from cache at None
[INFO|tokenization_utils_base.py:1741] 2022-04-19 01:27:33,400 >> loading file https://huggingface.co/gpt2-medium/resolve/main/tokenizer_config.json from cache at None
[INFO|configuration_utils.py:583] 2022-04-19 01:27:33,527 >> loading configuration file https://huggingface.co/gpt2-medium/resolve/main/config.json from cache at /home/ask9126/.cache/huggingface/transformers/3a7a4b7235202f93d14a4a5e8200709184c5b25a29d9cfa6b0ede5166adf0768.cf0ec4a33a38dc96108560e01338af4bd3360dd859385d451c35b41987ae73ff
[INFO|configuration_utils.py:620] 2022-04-19 01:27:33,527 >> Model config GPT2Config {
  "activation_function": "gelu_new",
  "architectures": [
    "GPT2LMHeadModel"
  ],
  "attn_pdrop": 0.1,
  "bos_token_id": 50256,
  "embd_pdrop": 0.1,
  "eos_token_id": 50256,
  "initializer_range": 0.02,
  "layer_norm_epsilon": 1e-05,
  "model_type": "gpt2",
  "n_ctx": 1024,
  "n_embd": 1024,
  "n_head": 16,
  "n_inner": null,
  "n_layer": 24,
  "n_positions": 1024,
  "n_special": 0,
  "predict_special_tokens": true,
  "resid_pdrop": 0.1,
  "scale_attn_weights": true,
  "summary_activation": null,
  "summary_first_dropout": 0.1,
  "summary_proj_to_labels": true,
  "summary_type": "cls_index",
  "summary_use_proj": true,
  "task_specific_params": {
    "text-generation": {
      "do_sample": true,
      "max_length": 50
    }
  },
  "transformers_version": "4.11.3",
  "use_cache": true,
  "vocab_size": 50257
}

  0%|          | 0/3 [00:00<?, ?it/s]100%|██████████| 3/3 [00:00<00:00, 55.36it/s]
Running tokenizer on dataset:   0%|          | 0/3 [00:00<?, ?ba/s]Running tokenizer on dataset:  33%|███▎      | 1/3 [00:00<00:00,  6.67ba/s]Running tokenizer on dataset: 100%|██████████| 3/3 [00:00<00:00, 12.97ba/s]Running tokenizer on dataset: 100%|██████████| 3/3 [00:00<00:00, 11.84ba/s]
Running tokenizer on dataset:   0%|          | 0/1 [00:00<?, ?ba/s]Running tokenizer on dataset: 100%|██████████| 1/1 [00:00<00:00, 33.39ba/s]
Running tokenizer on dataset:   0%|          | 0/3 [00:00<?, ?ba/s]Running tokenizer on dataset:  67%|██████▋   | 2/3 [00:00<00:00, 16.29ba/s]Running tokenizer on dataset: 100%|██████████| 3/3 [00:00<00:00, 14.09ba/s]
[INFO|configuration_utils.py:583] 2022-04-19 01:27:35,797 >> loading configuration file https://huggingface.co/gpt2-medium/resolve/main/config.json from cache at /home/ask9126/.cache/huggingface/transformers/3a7a4b7235202f93d14a4a5e8200709184c5b25a29d9cfa6b0ede5166adf0768.cf0ec4a33a38dc96108560e01338af4bd3360dd859385d451c35b41987ae73ff
[INFO|configuration_utils.py:620] 2022-04-19 01:27:35,798 >> Model config GPT2Config {
  "activation_function": "gelu_new",
  "architectures": [
    "GPT2LMHeadModel"
  ],
  "attn_pdrop": 0.1,
  "bos_token_id": 50256,
  "embd_pdrop": 0.1,
  "eos_token_id": 50256,
  "finetuning_task": "rte",
  "id2label": {
    "0": "entailment",
    "1": "not_entailment"
  },
  "initializer_range": 0.02,
  "label2id": {
    "entailment": 0,
    "not_entailment": 1
  },
  "layer_norm_epsilon": 1e-05,
  "model_type": "gpt2",
  "n_ctx": 1024,
  "n_embd": 1024,
  "n_head": 16,
  "n_inner": null,
  "n_layer": 24,
  "n_positions": 1024,
  "n_special": 0,
  "predict_special_tokens": true,
  "resid_pdrop": 0.1,
  "scale_attn_weights": true,
  "summary_activation": null,
  "summary_first_dropout": 0.1,
  "summary_proj_to_labels": true,
  "summary_type": "cls_index",
  "summary_use_proj": true,
  "task_specific_params": {
    "text-generation": {
      "do_sample": true,
      "max_length": 50
    }
  },
  "transformers_version": "4.11.3",
  "use_cache": true,
  "vocab_size": 50257
}

[INFO|file_utils.py:1664] 2022-04-19 01:27:35,981 >> https://huggingface.co/gpt2-medium/resolve/main/pytorch_model.bin not found in cache or force_download set to True, downloading to /home/ask9126/.cache/huggingface/transformers/tmp5v8wjzgq
Downloading:   0%|          | 0.00/1.42G [00:00<?, ?B/s]Downloading:   0%|          | 1.71M/1.42G [00:00<01:24, 17.9MB/s]Downloading:   1%|          | 7.99M/1.42G [00:00<00:38, 39.6MB/s]Downloading:   1%|          | 16.1M/1.42G [00:00<00:25, 57.9MB/s]Downloading:   2%|▏         | 24.0M/1.42G [00:00<00:26, 55.9MB/s]Downloading:   2%|▏         | 30.7M/1.42G [00:00<00:26, 55.8MB/s]Downloading:   2%|▏         | 36.0M/1.42G [00:00<00:30, 48.9MB/s]Downloading:   3%|▎         | 40.8M/1.42G [00:01<00:59, 24.8MB/s]Downloading:   3%|▎         | 48.0M/1.42G [00:01<00:47, 30.8MB/s]Downloading:   4%|▍         | 56.0M/1.42G [00:01<00:37, 39.3MB/s]Downloading:   4%|▍         | 63.4M/1.42G [00:01<00:30, 46.9MB/s]Downloading:   5%|▍         | 69.1M/1.42G [00:01<00:29, 49.1MB/s]Downloading:   5%|▌         | 74.8M/1.42G [00:01<00:34, 41.5MB/s]Downloading:   6%|▌         | 80.0M/1.42G [00:02<00:36, 39.4MB/s]Downloading:   6%|▌         | 87.8M/1.42G [00:02<00:32, 43.8MB/s]Downloading:   6%|▋         | 92.4M/1.42G [00:02<00:37, 37.5MB/s]Downloading:   7%|▋         | 96.3M/1.42G [00:02<00:43, 32.7MB/s]Downloading:   7%|▋         | 104M/1.42G [00:02<00:35, 39.8MB/s] Downloading:   7%|▋         | 108M/1.42G [00:02<00:34, 40.4MB/s]Downloading:   8%|▊         | 115M/1.42G [00:02<00:30, 46.6MB/s]Downloading:   8%|▊         | 120M/1.42G [00:03<00:28, 48.3MB/s]Downloading:   9%|▉         | 128M/1.42G [00:03<00:26, 51.9MB/s]Downloading:   9%|▉         | 134M/1.42G [00:03<00:38, 36.1MB/s]Downloading:  10%|▉         | 139M/1.42G [00:03<00:37, 36.9MB/s]Downloading:  10%|█         | 145M/1.42G [00:03<00:31, 43.4MB/s]Downloading:  10%|█         | 150M/1.42G [00:03<00:38, 35.0MB/s]Downloading:  11%|█         | 154M/1.42G [00:04<00:46, 29.4MB/s]Downloading:  11%|█         | 162M/1.42G [00:04<00:34, 39.7MB/s]Downloading:  12%|█▏        | 168M/1.42G [00:04<00:34, 38.5MB/s]Downloading:  12%|█▏        | 176M/1.42G [00:04<00:28, 46.5MB/s]Downloading:  13%|█▎        | 183M/1.42G [00:04<00:25, 51.6MB/s]Downloading:  13%|█▎        | 188M/1.42G [00:04<00:34, 38.8MB/s]Downloading:  13%|█▎        | 193M/1.42G [00:04<00:32, 40.0MB/s]Downloading:  14%|█▎        | 198M/1.42G [00:05<00:36, 35.7MB/s]Downloading:  14%|█▍        | 204M/1.42G [00:05<00:31, 41.6MB/s]Downloading:  15%|█▍        | 212M/1.42G [00:05<00:26, 49.9MB/s]Downloading:  15%|█▍        | 217M/1.42G [00:05<00:33, 38.4MB/s]Downloading:  15%|█▌        | 223M/1.42G [00:05<00:30, 42.0MB/s]Downloading:  16%|█▌        | 227M/1.42G [00:05<00:30, 42.6MB/s]Downloading:  16%|█▌        | 234M/1.42G [00:05<00:26, 47.5MB/s]Downloading:  17%|█▋        | 240M/1.42G [00:06<00:27, 46.0MB/s]Downloading:  17%|█▋        | 246M/1.42G [00:06<00:25, 50.3MB/s]Downloading:  17%|█▋        | 251M/1.42G [00:06<00:28, 44.4MB/s]Downloading:  18%|█▊        | 256M/1.42G [00:06<00:37, 33.1MB/s]Downloading:  18%|█▊        | 262M/1.42G [00:06<00:34, 36.3MB/s]Downloading:  18%|█▊        | 266M/1.42G [00:06<00:34, 36.3MB/s]Downloading:  19%|█▊        | 271M/1.42G [00:06<00:31, 39.2MB/s]Downloading:  19%|█▉        | 275M/1.42G [00:07<00:30, 40.2MB/s]Downloading:  19%|█▉        | 280M/1.42G [00:07<00:34, 35.6MB/s]Downloading:  20%|█▉        | 288M/1.42G [00:07<00:29, 41.8MB/s]Downloading:  20%|██        | 296M/1.42G [00:07<00:23, 51.2MB/s]Downloading:  21%|██        | 302M/1.42G [00:07<00:22, 53.6MB/s]Downloading:  21%|██        | 307M/1.42G [00:07<00:21, 54.6MB/s]Downloading:  22%|██▏       | 313M/1.42G [00:08<00:32, 36.5MB/s]Downloading:  22%|██▏       | 320M/1.42G [00:08<00:29, 40.0MB/s]Downloading:  23%|██▎       | 328M/1.42G [00:08<00:25, 45.8MB/s]Downloading:  23%|██▎       | 336M/1.42G [00:08<00:21, 53.9MB/s]Downloading:  24%|██▎       | 344M/1.42G [00:08<00:19, 60.8MB/s]Downloading:  24%|██▍       | 350M/1.42G [00:08<00:20, 55.4MB/s]Downloading:  25%|██▍       | 356M/1.42G [00:08<00:20, 55.9MB/s]Downloading:  25%|██▍       | 362M/1.42G [00:08<00:19, 57.4MB/s]Downloading:  25%|██▌       | 368M/1.42G [00:09<00:27, 41.5MB/s]Downloading:  26%|██▌       | 375M/1.42G [00:09<00:25, 44.3MB/s]Downloading:  26%|██▌       | 380M/1.42G [00:09<00:27, 40.3MB/s]Downloading:  27%|██▋       | 386M/1.42G [00:09<00:28, 39.3MB/s]Downloading:  27%|██▋       | 392M/1.42G [00:09<00:28, 39.4MB/s]Downloading:  28%|██▊       | 400M/1.42G [00:09<00:23, 47.7MB/s]Downloading:  28%|██▊       | 408M/1.42G [00:10<00:21, 50.0MB/s]Downloading:  29%|██▊       | 414M/1.42G [00:10<00:21, 51.7MB/s]Downloading:  29%|██▉       | 419M/1.42G [00:10<00:20, 51.6MB/s]Downloading:  29%|██▉       | 425M/1.42G [00:10<00:25, 43.0MB/s]Downloading:  30%|██▉       | 432M/1.42G [00:10<00:22, 47.2MB/s]Downloading:  30%|███       | 440M/1.42G [00:10<00:24, 42.5MB/s]Downloading:  31%|███       | 448M/1.42G [00:10<00:20, 50.3MB/s]Downloading:  31%|███▏      | 454M/1.42G [00:11<00:19, 52.8MB/s]Downloading:  32%|███▏      | 460M/1.42G [00:11<00:20, 51.8MB/s]Downloading:  32%|███▏      | 465M/1.42G [00:11<00:23, 44.4MB/s]Downloading:  33%|███▎      | 472M/1.42G [00:11<00:21, 48.3MB/s]Downloading:  33%|███▎      | 479M/1.42G [00:11<00:21, 46.6MB/s]Downloading:  33%|███▎      | 483M/1.42G [00:11<00:22, 45.7MB/s]Downloading:  34%|███▎      | 488M/1.42G [00:11<00:21, 46.2MB/s]Downloading:  34%|███▍      | 495M/1.42G [00:11<00:18, 52.8MB/s]Downloading:  34%|███▍      | 500M/1.42G [00:11<00:18, 52.6MB/s]Downloading:  35%|███▍      | 505M/1.42G [00:12<00:21, 46.2MB/s]Downloading:  35%|███▌      | 510M/1.42G [00:12<00:21, 46.4MB/s]Downloading:  35%|███▌      | 514M/1.42G [00:12<00:22, 44.4MB/s]Downloading:  36%|███▌      | 520M/1.42G [00:12<00:21, 45.0MB/s]Downloading:  36%|███▋      | 527M/1.42G [00:12<00:18, 51.8MB/s]Downloading:  37%|███▋      | 532M/1.42G [00:12<00:18, 51.5MB/s]Downloading:  37%|███▋      | 537M/1.42G [00:12<00:23, 41.3MB/s]Downloading:  37%|███▋      | 541M/1.42G [00:13<00:25, 36.9MB/s]Downloading:  38%|███▊      | 545M/1.42G [00:13<00:32, 29.0MB/s]Downloading:  38%|███▊      | 552M/1.42G [00:13<00:28, 33.1MB/s]Downloading:  39%|███▊      | 558M/1.42G [00:13<00:23, 39.3MB/s]Downloading:  39%|███▉      | 563M/1.42G [00:13<00:29, 31.2MB/s]Downloading:  39%|███▉      | 568M/1.42G [00:13<00:27, 34.1MB/s]Downloading:  40%|███▉      | 576M/1.42G [00:14<00:20, 44.3MB/s]Downloading:  40%|████      | 581M/1.42G [00:14<00:22, 41.2MB/s]Downloading:  40%|████      | 585M/1.42G [00:14<00:24, 36.8MB/s]Downloading:  41%|████      | 592M/1.42G [00:14<00:20, 44.1MB/s]Downloading:  41%|████▏     | 600M/1.42G [00:14<00:19, 46.0MB/s]Downloading:  42%|████▏     | 608M/1.42G [00:14<00:18, 47.3MB/s]Downloading:  42%|████▏     | 616M/1.42G [00:14<00:17, 49.4MB/s]Downloading:  43%|████▎     | 621M/1.42G [00:15<00:17, 49.7MB/s]Downloading:  43%|████▎     | 626M/1.42G [00:15<00:17, 48.9MB/s]Downloading:  44%|████▎     | 632M/1.42G [00:15<00:17, 48.0MB/s]Downloading:  44%|████▍     | 640M/1.42G [00:15<00:17, 48.0MB/s]Downloading:  45%|████▍     | 647M/1.42G [00:15<00:15, 53.4MB/s]Downloading:  45%|████▍     | 652M/1.42G [00:15<00:16, 52.1MB/s]Downloading:  45%|████▌     | 659M/1.42G [00:15<00:14, 58.3MB/s]Downloading:  46%|████▌     | 665M/1.42G [00:15<00:17, 46.8MB/s]Downloading:  46%|████▋     | 672M/1.42G [00:16<00:15, 51.1MB/s]Downloading:  47%|████▋     | 680M/1.42G [00:16<00:14, 54.6MB/s]Downloading:  47%|████▋     | 685M/1.42G [00:16<00:14, 54.8MB/s]Downloading:  48%|████▊     | 691M/1.42G [00:16<00:15, 50.2MB/s]Downloading:  48%|████▊     | 696M/1.42G [00:16<00:16, 49.3MB/s]Downloading:  49%|████▉     | 707M/1.42G [00:16<00:11, 66.0MB/s]Downloading:  49%|████▉     | 714M/1.42G [00:16<00:13, 57.8MB/s]Downloading:  50%|████▉     | 720M/1.42G [00:16<00:14, 54.0MB/s]Downloading:  50%|█████     | 728M/1.42G [00:17<00:12, 60.2MB/s]Downloading:  51%|█████     | 734M/1.42G [00:17<00:13, 56.1MB/s]Downloading:  51%|█████     | 739M/1.42G [00:17<00:14, 53.2MB/s]Downloading:  51%|█████▏    | 745M/1.42G [00:17<00:16, 45.9MB/s]Downloading:  52%|█████▏    | 749M/1.42G [00:17<00:18, 39.9MB/s]Downloading:  52%|█████▏    | 753M/1.42G [00:17<00:18, 39.2MB/s]Downloading:  52%|█████▏    | 760M/1.42G [00:17<00:16, 42.9MB/s]Downloading:  53%|█████▎    | 767M/1.42G [00:18<00:17, 40.3MB/s]Downloading:  53%|█████▎    | 771M/1.42G [00:18<00:18, 38.0MB/s]Downloading:  54%|█████▍    | 780M/1.42G [00:18<00:13, 52.6MB/s]Downloading:  54%|█████▍    | 786M/1.42G [00:18<00:13, 52.3MB/s]Downloading:  55%|█████▍    | 792M/1.42G [00:18<00:13, 52.9MB/s]Downloading:  55%|█████▌    | 800M/1.42G [00:18<00:12, 53.6MB/s]Downloading:  56%|█████▌    | 808M/1.42G [00:18<00:11, 57.6MB/s]Downloading:  56%|█████▌    | 815M/1.42G [00:19<00:12, 54.8MB/s]Downloading:  57%|█████▋    | 820M/1.42G [00:19<00:14, 44.8MB/s]Downloading:  57%|█████▋    | 825M/1.42G [00:19<00:16, 38.9MB/s]Downloading:  57%|█████▋    | 833M/1.42G [00:19<00:12, 50.0MB/s]Downloading:  58%|█████▊    | 840M/1.42G [00:19<00:12, 50.3MB/s]Downloading:  58%|█████▊    | 848M/1.42G [00:19<00:12, 49.7MB/s]Downloading:  59%|█████▉    | 855M/1.42G [00:19<00:11, 55.7MB/s]Downloading:  59%|█████▉    | 861M/1.42G [00:20<00:12, 49.2MB/s]Downloading:  60%|█████▉    | 866M/1.42G [00:20<00:12, 49.5MB/s]Downloading:  60%|██████    | 872M/1.42G [00:20<00:11, 52.6MB/s]Downloading:  61%|██████    | 880M/1.42G [00:20<00:10, 59.0MB/s]Downloading:  61%|██████▏   | 888M/1.42G [00:20<00:09, 60.3MB/s]Downloading:  62%|██████▏   | 894M/1.42G [00:20<00:10, 56.1MB/s]Downloading:  62%|██████▏   | 900M/1.42G [00:20<00:10, 54.4MB/s]Downloading:  62%|██████▏   | 905M/1.42G [00:20<00:10, 53.6MB/s]Downloading:  63%|██████▎   | 911M/1.42G [00:21<00:10, 51.8MB/s]Downloading:  63%|██████▎   | 916M/1.42G [00:21<00:11, 49.2MB/s]Downloading:  64%|██████▎   | 921M/1.42G [00:21<00:13, 40.9MB/s]Downloading:  64%|██████▍   | 925M/1.42G [00:21<00:17, 30.8MB/s]Downloading:  64%|██████▍   | 928M/1.42G [00:21<00:22, 24.7MB/s]Downloading:  65%|██████▍   | 938M/1.42G [00:21<00:13, 38.6MB/s]Downloading:  65%|██████▌   | 944M/1.42G [00:21<00:12, 43.5MB/s]Downloading:  66%|██████▌   | 951M/1.42G [00:22<00:10, 49.3MB/s]Downloading:  66%|██████▌   | 956M/1.42G [00:22<00:10, 48.7MB/s]Downloading:  66%|██████▋   | 962M/1.42G [00:22<00:11, 43.4MB/s]Downloading:  67%|██████▋   | 968M/1.42G [00:22<00:11, 43.0MB/s]Downloading:  67%|██████▋   | 976M/1.42G [00:22<00:10, 47.4MB/s]Downloading:  68%|██████▊   | 984M/1.42G [00:22<00:09, 53.4MB/s]Downloading:  68%|██████▊   | 992M/1.42G [00:22<00:09, 51.4MB/s]Downloading:  69%|██████▉   | 0.98G/1.42G [00:23<00:08, 58.5MB/s]Downloading:  69%|██████▉   | 0.98G/1.42G [00:23<00:07, 58.8MB/s]Downloading:  70%|██████▉   | 0.99G/1.42G [00:23<00:07, 58.5MB/s]Downloading:  70%|███████   | 0.99G/1.42G [00:23<00:07, 58.0MB/s]Downloading:  71%|███████   | 1.00G/1.42G [00:23<00:07, 60.4MB/s]Downloading:  71%|███████   | 1.01G/1.42G [00:23<00:06, 63.5MB/s]Downloading:  72%|███████▏  | 1.02G/1.42G [00:23<00:07, 54.5MB/s]Downloading:  72%|███████▏  | 1.02G/1.42G [00:23<00:07, 56.6MB/s]Downloading:  73%|███████▎  | 1.03G/1.42G [00:24<00:09, 43.7MB/s]Downloading:  73%|███████▎  | 1.04G/1.42G [00:24<00:07, 52.4MB/s]Downloading:  74%|███████▎  | 1.04G/1.42G [00:24<00:07, 50.3MB/s]Downloading:  74%|███████▍  | 1.05G/1.42G [00:24<00:07, 52.4MB/s]Downloading:  74%|███████▍  | 1.05G/1.42G [00:24<00:07, 54.9MB/s]Downloading:  75%|███████▍  | 1.06G/1.42G [00:24<00:07, 50.4MB/s]Downloading:  75%|███████▌  | 1.06G/1.42G [00:24<00:09, 40.5MB/s]Downloading:  75%|███████▌  | 1.07G/1.42G [00:25<00:09, 41.3MB/s]Downloading:  76%|███████▌  | 1.07G/1.42G [00:25<00:08, 41.4MB/s]Downloading:  76%|███████▌  | 1.08G/1.42G [00:25<00:08, 43.6MB/s]Downloading:  77%|███████▋  | 1.09G/1.42G [00:25<00:06, 53.6MB/s]Downloading:  77%|███████▋  | 1.09G/1.42G [00:25<00:05, 59.4MB/s]Downloading:  78%|███████▊  | 1.10G/1.42G [00:25<00:05, 57.9MB/s]Downloading:  78%|███████▊  | 1.11G/1.42G [00:25<00:05, 55.9MB/s]Downloading:  78%|███████▊  | 1.11G/1.42G [00:25<00:05, 55.0MB/s]Downloading:  79%|███████▉  | 1.12G/1.42G [00:25<00:04, 64.5MB/s]Downloading:  79%|███████▉  | 1.12G/1.42G [00:26<00:05, 54.5MB/s]Downloading:  80%|███████▉  | 1.13G/1.42G [00:26<00:07, 39.8MB/s]Downloading:  80%|████████  | 1.13G/1.42G [00:26<00:09, 32.9MB/s]Downloading:  81%|████████  | 1.14G/1.42G [00:26<00:07, 40.2MB/s]Downloading:  81%|████████  | 1.15G/1.42G [00:26<00:06, 47.3MB/s]Downloading:  82%|████████▏ | 1.16G/1.42G [00:26<00:05, 54.4MB/s]Downloading:  82%|████████▏ | 1.16G/1.42G [00:27<00:05, 49.1MB/s]Downloading:  83%|████████▎ | 1.17G/1.42G [00:27<00:04, 60.0MB/s]Downloading:  83%|████████▎ | 1.18G/1.42G [00:27<00:04, 63.2MB/s]Downloading:  84%|████████▎ | 1.18G/1.42G [00:27<00:04, 59.7MB/s]Downloading:  84%|████████▍ | 1.19G/1.42G [00:27<00:04, 52.9MB/s]Downloading:  84%|████████▍ | 1.20G/1.42G [00:27<00:05, 46.8MB/s]Downloading:  85%|████████▍ | 1.20G/1.42G [00:27<00:04, 50.5MB/s]Downloading:  85%|████████▌ | 1.21G/1.42G [00:28<00:05, 41.3MB/s]Downloading:  86%|████████▌ | 1.21G/1.42G [00:28<00:04, 46.0MB/s]Downloading:  86%|████████▌ | 1.22G/1.42G [00:28<00:04, 49.4MB/s]Downloading:  87%|████████▋ | 1.23G/1.42G [00:28<00:04, 48.0MB/s]Downloading:  87%|████████▋ | 1.23G/1.42G [00:28<00:03, 55.6MB/s]Downloading:  88%|████████▊ | 1.24G/1.42G [00:28<00:03, 61.6MB/s]Downloading:  88%|████████▊ | 1.25G/1.42G [00:28<00:02, 66.7MB/s]Downloading:  89%|████████▊ | 1.26G/1.42G [00:28<00:02, 62.2MB/s]Downloading:  89%|████████▉ | 1.26G/1.42G [00:29<00:03, 44.7MB/s]Downloading:  90%|████████▉ | 1.27G/1.42G [00:29<00:03, 47.6MB/s]Downloading:  90%|████████▉ | 1.27G/1.42G [00:29<00:03, 47.0MB/s]Downloading:  91%|█████████ | 1.28G/1.42G [00:29<00:02, 50.1MB/s]Downloading:  91%|█████████ | 1.29G/1.42G [00:29<00:02, 54.6MB/s]Downloading:  92%|█████████▏| 1.30G/1.42G [00:29<00:02, 54.4MB/s]Downloading:  92%|█████████▏| 1.30G/1.42G [00:29<00:02, 54.1MB/s]Downloading:  93%|█████████▎| 1.31G/1.42G [00:30<00:01, 56.4MB/s]Downloading:  93%|█████████▎| 1.32G/1.42G [00:30<00:02, 51.8MB/s]Downloading:  93%|█████████▎| 1.32G/1.42G [00:30<00:01, 56.2MB/s]Downloading:  94%|█████████▍| 1.33G/1.42G [00:30<00:01, 52.3MB/s]Downloading:  94%|█████████▍| 1.33G/1.42G [00:30<00:01, 55.5MB/s]Downloading:  95%|█████████▍| 1.34G/1.42G [00:30<00:01, 47.9MB/s]Downloading:  95%|█████████▍| 1.34G/1.42G [00:30<00:01, 49.3MB/s]Downloading:  95%|█████████▌| 1.35G/1.42G [00:30<00:01, 55.7MB/s]Downloading:  96%|█████████▌| 1.36G/1.42G [00:31<00:01, 51.6MB/s]Downloading:  96%|█████████▌| 1.36G/1.42G [00:31<00:01, 49.5MB/s]Downloading:  97%|█████████▋| 1.37G/1.42G [00:31<00:01, 48.8MB/s]Downloading:  97%|█████████▋| 1.37G/1.42G [00:31<00:00, 57.5MB/s]Downloading:  98%|█████████▊| 1.38G/1.42G [00:31<00:00, 47.9MB/s]Downloading:  98%|█████████▊| 1.39G/1.42G [00:31<00:00, 53.1MB/s]Downloading:  98%|█████████▊| 1.39G/1.42G [00:31<00:00, 48.6MB/s]Downloading:  99%|█████████▉| 1.40G/1.42G [00:31<00:00, 48.5MB/s]Downloading:  99%|█████████▉| 1.41G/1.42G [00:32<00:00, 58.3MB/s]Downloading: 100%|█████████▉| 1.41G/1.42G [00:32<00:00, 58.2MB/s]Downloading: 100%|██████████| 1.42G/1.42G [00:32<00:00, 47.2MB/s]
[INFO|file_utils.py:1668] 2022-04-19 01:28:09,156 >> storing https://huggingface.co/gpt2-medium/resolve/main/pytorch_model.bin in cache at /home/ask9126/.cache/huggingface/transformers/6249eef5c8c1fcfccf9f36fc2e59301b109ac4036d8ebbee9c2b7f7e47f440bd.2538e2565f9e439a3668b981faf959c8b490b36dd631f3c4cd992519b2dd36f1
[INFO|file_utils.py:1676] 2022-04-19 01:28:09,165 >> creating metadata file for /home/ask9126/.cache/huggingface/transformers/6249eef5c8c1fcfccf9f36fc2e59301b109ac4036d8ebbee9c2b7f7e47f440bd.2538e2565f9e439a3668b981faf959c8b490b36dd631f3c4cd992519b2dd36f1
[INFO|modeling_utils.py:1323] 2022-04-19 01:28:09,177 >> loading weights file https://huggingface.co/gpt2-medium/resolve/main/pytorch_model.bin from cache at /home/ask9126/.cache/huggingface/transformers/6249eef5c8c1fcfccf9f36fc2e59301b109ac4036d8ebbee9c2b7f7e47f440bd.2538e2565f9e439a3668b981faf959c8b490b36dd631f3c4cd992519b2dd36f1
[WARNING|modeling_utils.py:1579] 2022-04-19 01:28:24,169 >> Some weights of the model checkpoint at gpt2-medium were not used when initializing GPT2BasePrefixForSequenceClassification: ['h.6.attn.bias', 'h.3.attn.bias', 'h.17.attn.bias', 'h.10.mlp.c_fc.weight', 'h.10.mlp.c_proj.bias', 'h.19.mlp.c_proj.bias', 'h.20.mlp.c_fc.weight', 'h.11.attn.c_attn.bias', 'h.14.mlp.c_proj.weight', 'h.0.attn.c_attn.bias', 'h.21.mlp.c_proj.weight', 'h.19.mlp.c_fc.bias', 'h.7.attn.bias', 'h.7.mlp.c_fc.weight', 'h.10.attn.c_attn.bias', 'h.10.ln_2.bias', 'h.22.attn.bias', 'h.20.mlp.c_fc.bias', 'h.21.ln_1.weight', 'h.23.mlp.c_fc.bias', 'h.4.ln_1.bias', 'h.16.attn.c_attn.weight', 'h.22.ln_2.bias', 'h.17.mlp.c_fc.bias', 'h.9.attn.bias', 'h.3.attn.c_attn.bias', 'h.6.attn.c_proj.weight', 'h.13.attn.c_attn.weight', 'h.7.mlp.c_proj.bias', 'h.20.attn.c_proj.weight', 'wpe.weight', 'h.10.attn.c_proj.weight', 'h.5.attn.c_attn.weight', 'h.11.attn.c_attn.weight', 'h.12.attn.c_proj.bias', 'h.23.ln_2.bias', 'h.19.attn.c_proj.bias', 'h.21.attn.c_attn.weight', 'h.6.ln_1.bias', 'h.10.attn.c_attn.weight', 'h.21.attn.c_proj.weight', 'h.17.mlp.c_proj.bias', 'h.3.mlp.c_fc.weight', 'h.6.mlp.c_proj.weight', 'h.8.ln_2.bias', 'h.1.mlp.c_fc.weight', 'h.8.ln_2.weight', 'h.17.attn.c_attn.weight', 'h.21.mlp.c_proj.bias', 'h.17.ln_1.weight', 'h.20.mlp.c_proj.weight', 'h.15.attn.bias', 'ln_f.bias', 'h.14.mlp.c_fc.weight', 'h.12.mlp.c_fc.weight', 'h.2.mlp.c_fc.bias', 'h.15.ln_1.bias', 'h.4.ln_1.weight', 'h.23.attn.bias', 'h.2.attn.bias', 'h.18.ln_2.bias', 'h.4.attn.c_attn.bias', 'h.18.ln_1.weight', 'h.2.attn.c_proj.bias', 'h.21.mlp.c_fc.bias', 'h.16.mlp.c_proj.weight', 'h.16.ln_1.bias', 'h.5.attn.c_attn.bias', 'h.20.ln_2.bias', 'h.4.mlp.c_fc.bias', 'h.23.mlp.c_fc.weight', 'h.1.ln_1.bias', 'h.11.mlp.c_fc.weight', 'h.14.attn.c_attn.weight', 'h.13.mlp.c_proj.weight', 'h.1.attn.c_proj.weight', 'h.7.attn.c_proj.bias', 'h.0.mlp.c_fc.weight', 'h.9.ln_1.weight', 'h.21.attn.c_proj.bias', 'h.8.attn.c_proj.bias', 'h.3.attn.c_proj.bias', 'h.7.ln_2.bias', 'h.8.mlp.c_proj.bias', 'h.8.mlp.c_fc.weight', 'wte.weight', 'h.2.ln_2.bias', 'h.12.ln_1.weight', 'h.23.attn.c_proj.weight', 'h.18.attn.c_attn.bias', 'h.23.ln_1.weight', 'h.15.attn.c_attn.weight', 'h.4.attn.bias', 'h.8.mlp.c_fc.bias', 'h.13.attn.c_proj.weight', 'h.19.attn.c_attn.weight', 'h.18.attn.c_proj.bias', 'h.13.attn.c_proj.bias', 'h.16.attn.c_attn.bias', 'h.7.ln_1.weight', 'h.13.ln_1.weight', 'h.3.ln_2.bias', 'h.22.attn.c_attn.weight', 'h.12.mlp.c_proj.bias', 'h.11.mlp.c_proj.bias', 'h.13.mlp.c_fc.weight', 'h.22.ln_2.weight', 'h.10.mlp.c_proj.weight', 'h.18.mlp.c_fc.bias', 'h.11.ln_2.weight', 'h.3.mlp.c_fc.bias', 'h.20.attn.bias', 'h.23.ln_2.weight', 'h.14.ln_2.bias', 'h.12.ln_2.bias', 'h.15.ln_2.weight', 'h.19.attn.bias', 'h.11.mlp.c_proj.weight', 'h.10.ln_2.weight', 'h.0.ln_2.bias', 'h.4.ln_2.weight', 'h.6.ln_2.bias', 'h.8.mlp.c_proj.weight', 'h.12.attn.c_attn.bias', 'h.14.attn.c_proj.weight', 'h.20.attn.c_attn.weight', 'h.9.mlp.c_proj.bias', 'h.7.attn.c_attn.bias', 'h.15.mlp.c_proj.bias', 'h.22.attn.c_proj.weight', 'h.1.attn.c_attn.weight', 'h.18.attn.c_proj.weight', 'h.11.ln_2.bias', 'h.19.ln_1.bias', 'h.1.mlp.c_proj.bias', 'h.19.ln_2.bias', 'h.0.ln_2.weight', 'h.6.mlp.c_proj.bias', 'h.13.ln_2.weight', 'h.13.ln_1.bias', 'h.8.ln_1.bias', 'h.7.attn.c_proj.weight', 'h.9.ln_1.bias', 'h.15.mlp.c_fc.bias', 'h.3.attn.c_attn.weight', 'h.8.attn.bias', 'h.14.mlp.c_proj.bias', 'h.9.mlp.c_fc.weight', 'h.7.mlp.c_proj.weight', 'h.11.attn.bias', 'h.18.ln_2.weight', 'h.13.ln_2.bias', 'h.6.ln_2.weight', 'h.8.attn.c_attn.bias', 'h.23.attn.c_proj.bias', 'h.7.attn.c_attn.weight', 'h.15.ln_1.weight', 'h.21.attn.c_attn.bias', 'h.5.attn.bias', 'h.17.mlp.c_proj.weight', 'h.12.attn.c_proj.weight', 'h.0.attn.c_proj.weight', 'h.8.attn.c_proj.weight', 'h.17.attn.c_proj.weight', 'h.6.ln_1.weight', 'h.0.mlp.c_proj.weight', 'h.1.attn.c_proj.bias', 'h.22.ln_1.weight', 'h.16.mlp.c_fc.weight', 'h.18.attn.c_attn.weight', 'h.22.mlp.c_proj.weight', 'h.22.mlp.c_proj.bias', 'h.13.attn.bias', 'h.4.mlp.c_fc.weight', 'h.22.attn.c_proj.bias', 'h.16.attn.c_proj.bias', 'h.5.ln_2.bias', 'h.23.ln_1.bias', 'h.5.mlp.c_proj.bias', 'h.3.mlp.c_proj.bias', 'h.5.mlp.c_proj.weight', 'h.14.ln_2.weight', 'h.16.ln_2.weight', 'h.19.attn.c_attn.bias', 'h.13.attn.c_attn.bias', 'h.15.attn.c_proj.weight', 'h.17.attn.c_attn.bias', 'h.23.mlp.c_proj.bias', 'h.0.ln_1.bias', 'h.2.ln_2.weight', 'h.17.ln_2.bias', 'h.23.attn.c_attn.weight', 'h.9.attn.c_attn.weight', 'h.3.ln_2.weight', 'h.14.attn.c_attn.bias', 'h.17.attn.c_proj.bias', 'h.9.attn.c_proj.bias', 'h.20.ln_1.bias', 'h.8.ln_1.weight', 'h.23.mlp.c_proj.weight', 'h.22.ln_1.bias', 'h.15.attn.c_attn.bias', 'h.19.mlp.c_proj.weight', 'h.17.ln_1.bias', 'h.15.mlp.c_fc.weight', 'h.21.ln_2.weight', 'h.4.mlp.c_proj.bias', 'h.0.ln_1.weight', 'h.14.mlp.c_fc.bias', 'h.10.attn.c_proj.bias', 'h.15.ln_2.bias', 'h.11.ln_1.weight', 'h.23.attn.c_attn.bias', 'h.1.attn.c_attn.bias', 'h.1.mlp.c_proj.weight', 'h.11.attn.c_proj.weight', 'h.12.mlp.c_fc.bias', 'ln_f.weight', 'h.14.attn.c_proj.bias', 'h.20.ln_1.weight', 'h.21.ln_1.bias', 'h.11.attn.c_proj.bias', 'h.16.attn.bias', 'h.4.attn.c_proj.bias', 'h.5.ln_2.weight', 'h.22.mlp.c_fc.weight', 'h.6.attn.c_attn.weight', 'h.4.attn.c_attn.weight', 'h.9.mlp.c_proj.weight', 'h.2.ln_1.weight', 'h.1.mlp.c_fc.bias', 'h.18.mlp.c_fc.weight', 'h.21.attn.bias', 'h.5.mlp.c_fc.weight', 'h.2.attn.c_proj.weight', 'h.19.mlp.c_fc.weight', 'h.1.ln_2.bias', 'h.4.mlp.c_proj.weight', 'h.19.attn.c_proj.weight', 'h.2.mlp.c_fc.weight', 'h.1.ln_1.weight', 'h.7.ln_2.weight', 'h.2.attn.c_attn.bias', 'h.18.ln_1.bias', 'h.9.mlp.c_fc.bias', 'h.9.ln_2.bias', 'h.12.attn.c_attn.weight', 'h.20.attn.c_proj.bias', 'h.18.attn.bias', 'h.5.attn.c_proj.weight', 'h.16.mlp.c_proj.bias', 'h.12.attn.bias', 'h.22.mlp.c_fc.bias', 'h.18.mlp.c_proj.weight', 'h.16.ln_1.weight', 'h.20.ln_2.weight', 'h.3.attn.c_proj.weight', 'h.0.mlp.c_fc.bias', 'h.19.ln_1.weight', 'h.12.ln_1.bias', 'h.13.mlp.c_proj.bias', 'h.7.ln_1.bias', 'h.3.ln_1.bias', 'h.9.attn.c_proj.weight', 'h.2.mlp.c_proj.weight', 'h.1.ln_2.weight', 'h.16.ln_2.bias', 'h.12.mlp.c_proj.weight', 'h.6.mlp.c_fc.weight', 'h.15.mlp.c_proj.weight', 'h.0.mlp.c_proj.bias', 'h.10.ln_1.weight', 'h.20.attn.c_attn.bias', 'h.14.ln_1.weight', 'h.2.ln_1.bias', 'h.12.ln_2.weight', 'h.3.mlp.c_proj.weight', 'h.5.attn.c_proj.bias', 'h.21.mlp.c_fc.weight', 'h.0.attn.c_proj.bias', 'h.15.attn.c_proj.bias', 'h.11.mlp.c_fc.bias', 'h.4.ln_2.bias', 'h.17.mlp.c_fc.weight', 'h.14.ln_1.bias', 'h.1.attn.bias', 'h.6.attn.c_attn.bias', 'h.11.ln_1.bias', 'h.2.attn.c_attn.weight', 'h.9.ln_2.weight', 'h.5.mlp.c_fc.bias', 'h.14.attn.bias', 'h.8.attn.c_attn.weight', 'h.18.mlp.c_proj.bias', 'h.6.attn.c_proj.bias', 'h.0.attn.c_attn.weight', 'h.20.mlp.c_proj.bias', 'h.6.mlp.c_fc.bias', 'h.5.ln_1.weight', 'h.21.ln_2.bias', 'h.10.mlp.c_fc.bias', 'h.10.attn.bias', 'h.22.attn.c_attn.bias', 'h.16.attn.c_proj.weight', 'h.17.ln_2.weight', 'h.19.ln_2.weight', 'h.10.ln_1.bias', 'h.7.mlp.c_fc.bias', 'h.16.mlp.c_fc.bias', 'h.2.mlp.c_proj.bias', 'h.13.mlp.c_fc.bias', 'h.4.attn.c_proj.weight', 'h.3.ln_1.weight', 'h.5.ln_1.bias', 'h.0.attn.bias', 'h.9.attn.c_attn.bias']
- This IS expected if you are initializing GPT2BasePrefixForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing GPT2BasePrefixForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
[WARNING|modeling_utils.py:1590] 2022-04-19 01:28:24,170 >> Some weights of GPT2BasePrefixForSequenceClassification were not initialized from the model checkpoint at gpt2-medium and are newly initialized: ['gpt2.transformer.h.23.ln_2.bias', 'gpt2.transformer.h.1.attn.bias', 'gpt2.transformer.h.7.ln_2.weight', 'gpt2.transformer.h.16.ln_2.weight', 'gpt2.transformer.h.4.mlp.c_fc.bias', 'gpt2.transformer.h.18.attn.c_proj.weight', 'gpt2.transformer.h.3.ln_1.weight', 'gpt2.transformer.h.14.ln_2.weight', 'gpt2.transformer.h.0.mlp.c_proj.weight', 'gpt2.transformer.h.8.mlp.c_fc.bias', 'gpt2.transformer.h.5.mlp.c_fc.bias', 'gpt2.transformer.h.20.attn.c_proj.weight', 'gpt2.transformer.h.2.ln_2.weight', 'gpt2.transformer.h.10.attn.bias', 'gpt2.transformer.h.9.mlp.c_proj.bias', 'gpt2.transformer.h.0.ln_2.weight', 'gpt2.transformer.h.1.ln_2.bias', 'gpt2.transformer.h.20.ln_2.weight', 'gpt2.transformer.h.0.attn.masked_bias', 'gpt2.transformer.h.8.attn.c_proj.bias', 'gpt2.transformer.h.10.mlp.c_proj.bias', 'gpt2.transformer.h.22.ln_2.bias', 'gpt2.transformer.h.10.ln_2.weight', 'gpt2.transformer.h.18.ln_2.bias', 'gpt2.transformer.h.1.attn.c_attn.bias', 'gpt2.transformer.h.15.attn.c_proj.bias', 'gpt2.transformer.h.19.attn.c_attn.bias', 'gpt2.transformer.h.21.ln_1.weight', 'gpt2.transformer.h.7.attn.c_attn.bias', 'gpt2.transformer.h.7.attn.c_attn.weight', 'gpt2.transformer.h.6.attn.c_attn.bias', 'gpt2.transformer.h.4.mlp.c_proj.bias', 'gpt2.transformer.h.19.ln_2.weight', 'gpt2.transformer.h.23.attn.bias', 'gpt2.transformer.h.8.mlp.c_fc.weight', 'gpt2.transformer.h.21.attn.masked_bias', 'gpt2.transformer.h.3.attn.c_attn.bias', 'gpt2.transformer.h.3.mlp.c_fc.bias', 'gpt2.transformer.h.10.mlp.c_fc.bias', 'gpt2.transformer.h.15.attn.c_attn.bias', 'gpt2.transformer.h.15.attn.masked_bias', 'gpt2.transformer.h.0.mlp.c_proj.bias', 'gpt2.transformer.h.0.mlp.c_fc.weight', 'gpt2.transformer.h.7.mlp.c_fc.weight', 'gpt2.transformer.h.15.mlp.c_proj.weight', 'gpt2.transformer.h.20.mlp.c_proj.weight', 'gpt2.transformer.h.23.ln_1.bias', 'gpt2.transformer.h.4.mlp.c_proj.weight', 'gpt2.transformer.h.14.ln_1.weight', 'gpt2.transformer.h.16.ln_1.weight', 'gpt2.transformer.h.21.attn.bias', 'gpt2.transformer.h.23.attn.c_proj.bias', 'gpt2.transformer.h.23.mlp.c_proj.bias', 'gpt2.transformer.h.10.ln_1.weight', 'gpt2.transformer.h.15.ln_2.bias', 'gpt2.transformer.h.18.mlp.c_proj.bias', 'gpt2.transformer.h.8.ln_2.bias', 'gpt2.transformer.h.19.attn.c_attn.weight', 'gpt2.transformer.h.2.mlp.c_proj.weight', 'gpt2.transformer.h.9.attn.c_attn.bias', 'gpt2.transformer.h.10.attn.c_proj.weight', 'gpt2.transformer.h.15.mlp.c_fc.weight', 'gpt2.transformer.h.5.attn.c_attn.bias', 'gpt2.transformer.h.8.mlp.c_proj.weight', 'gpt2.transformer.h.4.attn.c_proj.weight', 'gpt2.transformer.ln_f.bias', 'gpt2.transformer.h.17.ln_2.bias', 'gpt2.transformer.h.5.ln_1.weight', 'gpt2.transformer.h.8.ln_2.weight', 'gpt2.transformer.h.17.attn.c_proj.bias', 'gpt2.transformer.h.2.mlp.c_proj.bias', 'gpt2.transformer.h.7.ln_1.weight', 'gpt2.transformer.h.11.mlp.c_fc.weight', 'gpt2.transformer.h.16.ln_1.bias', 'gpt2.transformer.h.19.attn.masked_bias', 'gpt2.transformer.h.4.attn.c_proj.bias', 'gpt2.transformer.h.10.ln_2.bias', 'gpt2.transformer.h.17.attn.masked_bias', 'gpt2.transformer.h.6.ln_1.weight', 'gpt2.transformer.h.10.attn.c_proj.bias', 'gpt2.transformer.h.9.attn.c_attn.weight', 'gpt2.transformer.h.12.attn.bias', 'gpt2.transformer.h.4.attn.c_attn.bias', 'gpt2.transformer.h.1.mlp.c_proj.bias', 'gpt2.transformer.h.0.ln_1.bias', 'gpt2.transformer.h.8.mlp.c_proj.bias', 'gpt2.transformer.h.13.mlp.c_fc.weight', 'gpt2.transformer.h.20.attn.c_proj.bias', 'gpt2.transformer.h.11.attn.masked_bias', 'gpt2.transformer.h.13.attn.c_proj.bias', 'gpt2.transformer.h.11.attn.bias', 'gpt2.transformer.h.1.attn.c_proj.weight', 'gpt2.transformer.h.6.attn.masked_bias', 'gpt2.transformer.h.16.attn.c_attn.bias', 'gpt2.transformer.h.21.attn.c_attn.weight', 'gpt2.transformer.h.16.attn.bias', 'gpt2.transformer.h.2.mlp.c_fc.bias', 'gpt2.transformer.h.16.mlp.c_proj.bias', 'gpt2.transformer.h.23.ln_2.weight', 'gpt2.transformer.h.22.attn.c_attn.bias', 'gpt2.transformer.h.14.mlp.c_fc.bias', 'gpt2.transformer.h.13.mlp.c_proj.bias', 'gpt2.transformer.h.16.mlp.c_fc.bias', 'gpt2.transformer.h.11.mlp.c_proj.weight', 'gpt2.transformer.h.14.attn.bias', 'gpt2.transformer.h.17.ln_2.weight', 'gpt2.transformer.h.9.ln_2.bias', 'gpt2.transformer.h.13.ln_1.bias', 'gpt2.transformer.h.5.attn.masked_bias', 'gpt2.transformer.h.22.ln_2.weight', 'gpt2.transformer.h.8.attn.c_attn.weight', 'gpt2.transformer.h.12.ln_2.bias', 'gpt2.transformer.h.3.attn.bias', 'gpt2.transformer.h.11.ln_2.bias', 'gpt2.transformer.h.5.attn.c_proj.bias', 'gpt2.transformer.h.6.mlp.c_proj.weight', 'gpt2.transformer.h.2.ln_1.bias', 'gpt2.transformer.h.19.mlp.c_fc.weight', 'gpt2.transformer.h.17.attn.bias', 'gpt2.transformer.h.9.attn.masked_bias', 'gpt2.transformer.h.9.attn.bias', 'gpt2.transformer.h.9.ln_1.bias', 'gpt2.transformer.h.20.ln_1.bias', 'gpt2.transformer.h.20.ln_1.weight', 'gpt2.transformer.h.14.attn.c_proj.bias', 'gpt2.transformer.h.15.ln_1.bias', 'gpt2.transformer.h.8.attn.c_proj.weight', 'gpt2.transformer.h.10.mlp.c_proj.weight', 'gpt2.transformer.h.20.attn.bias', 'gpt2.transformer.h.5.ln_1.bias', 'gpt2.transformer.h.22.mlp.c_fc.bias', 'gpt2.transformer.h.9.mlp.c_fc.weight', 'gpt2.transformer.h.17.mlp.c_fc.bias', 'gpt2.transformer.h.19.mlp.c_proj.bias', 'gpt2.transformer.h.22.mlp.c_fc.weight', 'gpt2.transformer.h.4.ln_2.bias', 'gpt2.transformer.h.16.mlp.c_proj.weight', 'gpt2.transformer.h.18.attn.c_attn.weight', 'gpt2.transformer.h.22.ln_1.weight', 'gpt2.transformer.h.13.ln_2.bias', 'gpt2.transformer.h.21.attn.c_proj.weight', 'gpt2.transformer.h.10.attn.c_attn.weight', 'gpt2.transformer.h.19.attn.bias', 'gpt2.transformer.h.23.attn.c_attn.weight', 'gpt2.transformer.h.18.mlp.c_fc.weight', 'gpt2.transformer.h.6.attn.c_proj.bias', 'gpt2.transformer.h.14.attn.c_attn.weight', 'gpt2.transformer.h.16.attn.c_proj.bias', 'gpt2.transformer.wte.weight', 'gpt2.transformer.h.1.attn.masked_bias', 'gpt2.transformer.h.0.attn.c_attn.weight', 'gpt2.score.weight', 'gpt2.transformer.h.19.ln_1.bias', 'gpt2.transformer.h.22.ln_1.bias', 'gpt2.transformer.h.3.ln_2.weight', 'gpt2.transformer.h.3.mlp.c_fc.weight', 'gpt2.transformer.h.19.attn.c_proj.weight', 'gpt2.transformer.h.4.ln_2.weight', 'gpt2.transformer.h.5.mlp.c_fc.weight', 'gpt2.transformer.h.4.ln_1.weight', 'gpt2.transformer.h.1.attn.c_proj.bias', 'gpt2.transformer.h.12.mlp.c_proj.weight', 'gpt2.transformer.h.11.ln_2.weight', 'gpt2.transformer.h.1.mlp.c_fc.weight', 'gpt2.transformer.h.15.attn.c_proj.weight', 'gpt2.transformer.h.12.attn.c_attn.weight', 'gpt2.transformer.h.9.ln_1.weight', 'gpt2.transformer.h.20.attn.c_attn.weight', 'gpt2.transformer.h.11.attn.c_attn.bias', 'gpt2.transformer.h.12.attn.c_proj.weight', 'gpt2.transformer.h.1.mlp.c_fc.bias', 'gpt2.transformer.h.5.ln_2.weight', 'gpt2.transformer.h.15.attn.bias', 'gpt2.transformer.h.16.attn.masked_bias', 'gpt2.transformer.h.0.attn.c_proj.weight', 'gpt2.transformer.h.22.attn.c_attn.weight', 'gpt2.transformer.h.22.attn.c_proj.weight', 'gpt2.transformer.h.1.ln_1.weight', 'gpt2.transformer.h.17.ln_1.bias', 'gpt2.transformer.h.8.ln_1.bias', 'gpt2.transformer.h.2.mlp.c_fc.weight', 'gpt2.transformer.h.7.mlp.c_fc.bias', 'gpt2.transformer.h.17.mlp.c_proj.weight', 'gpt2.transformer.h.21.mlp.c_fc.weight', 'gpt2.transformer.h.4.attn.bias', 'gpt2.transformer.h.21.attn.c_attn.bias', 'gpt2.transformer.h.4.attn.masked_bias', 'gpt2.transformer.h.6.ln_1.bias', 'gpt2.transformer.h.7.ln_1.bias', 'gpt2.transformer.h.18.ln_2.weight', 'gpt2.transformer.h.22.mlp.c_proj.weight', 'gpt2.transformer.h.5.ln_2.bias', 'gpt2.transformer.h.12.attn.c_attn.bias', 'gpt2.transformer.h.5.mlp.c_proj.weight', 'gpt2.transformer.h.3.mlp.c_proj.weight', 'gpt2.transformer.h.8.ln_1.weight', 'gpt2.transformer.h.15.mlp.c_proj.bias', 'gpt2.transformer.h.10.ln_1.bias', 'gpt2.transformer.h.9.attn.c_proj.bias', 'gpt2.transformer.h.14.mlp.c_proj.bias', 'gpt2.transformer.h.22.attn.masked_bias', 'gpt2.transformer.h.1.attn.c_attn.weight', 'gpt2.transformer.h.1.ln_2.weight', 'gpt2.transformer.h.18.mlp.c_proj.weight', 'gpt2.transformer.h.8.attn.c_attn.bias', 'gpt2.transformer.h.23.attn.masked_bias', 'gpt2.transformer.h.10.attn.c_attn.bias', 'gpt2.transformer.h.15.attn.c_attn.weight', 'gpt2.transformer.h.14.attn.c_proj.weight', 'gpt2.transformer.h.10.mlp.c_fc.weight', 'gpt2.transformer.h.12.attn.masked_bias', 'gpt2.transformer.h.12.ln_2.weight', 'gpt2.transformer.h.11.ln_1.bias', 'gpt2.transformer.h.0.mlp.c_fc.bias', 'gpt2.transformer.h.16.ln_2.bias', 'gpt2.transformer.h.17.ln_1.weight', 'gpt2.transformer.h.0.ln_2.bias', 'gpt2.transformer.h.12.ln_1.bias', 'gpt2.transformer.ln_f.weight', 'gpt2.transformer.h.15.ln_2.weight', 'gpt2.transformer.h.14.mlp.c_proj.weight', 'gpt2.transformer.h.18.ln_1.weight', 'gpt2.transformer.h.2.ln_2.bias', 'gpt2.transformer.h.21.ln_2.bias', 'gpt2.transformer.h.0.attn.c_proj.bias', 'gpt2.transformer.h.13.attn.masked_bias', 'gpt2.transformer.h.0.attn.bias', 'gpt2.transformer.h.8.attn.masked_bias', 'gpt2.transformer.h.18.ln_1.bias', 'gpt2.transformer.h.17.attn.c_proj.weight', 'gpt2.transformer.h.3.ln_1.bias', 'gpt2.transformer.h.6.attn.c_attn.weight', 'gpt2.transformer.h.21.ln_1.bias', 'gpt2.transformer.h.17.mlp.c_proj.bias', 'gpt2.transformer.h.23.mlp.c_fc.bias', 'gpt2.transformer.h.7.mlp.c_proj.bias', 'gpt2.transformer.h.14.mlp.c_fc.weight', 'gpt2.transformer.h.3.attn.masked_bias', 'gpt2.transformer.h.5.attn.bias', 'gpt2.transformer.h.23.mlp.c_proj.weight', 'gpt2.transformer.wpe.weight', 'gpt2.transformer.h.20.mlp.c_fc.weight', 'gpt2.transformer.h.13.attn.c_proj.weight', 'gpt2.transformer.h.7.attn.c_proj.weight', 'gpt2.transformer.h.11.attn.c_attn.weight', 'gpt2.transformer.h.2.attn.c_proj.weight', 'gpt2.transformer.h.2.attn.c_attn.bias', 'gpt2.transformer.h.13.mlp.c_proj.weight', 'gpt2.transformer.h.16.attn.c_proj.weight', 'gpt2.transformer.h.6.mlp.c_fc.bias', 'gpt2.transformer.h.18.attn.c_proj.bias', 'gpt2.transformer.h.8.attn.bias', 'gpt2.transformer.h.9.mlp.c_fc.bias', 'gpt2.transformer.h.11.attn.c_proj.bias', 'gpt2.transformer.h.20.mlp.c_fc.bias', 'gpt2.transformer.h.2.attn.c_proj.bias', 'gpt2.transformer.h.6.attn.bias', 'gpt2.transformer.h.13.attn.c_attn.weight', 'gpt2.transformer.h.17.attn.c_attn.weight', 'gpt2.transformer.h.18.attn.c_attn.bias', 'gpt2.transformer.h.7.attn.bias', 'gpt2.transformer.h.9.mlp.c_proj.weight', 'gpt2.transformer.h.7.attn.masked_bias', 'gpt2.transformer.h.20.mlp.c_proj.bias', 'gpt2.transformer.h.21.mlp.c_proj.bias', 'gpt2.transformer.h.16.attn.c_attn.weight', 'gpt2.transformer.h.18.attn.bias', 'gpt2.transformer.h.6.attn.c_proj.weight', 'classifier.bias', 'gpt2.transformer.h.3.ln_2.bias', 'gpt2.transformer.h.12.mlp.c_fc.bias', 'gpt2.transformer.h.13.attn.c_attn.bias', 'gpt2.transformer.h.5.attn.c_attn.weight', 'gpt2.transformer.h.12.ln_1.weight', 'gpt2.transformer.h.0.attn.c_attn.bias', 'gpt2.transformer.h.22.attn.bias', 'gpt2.transformer.h.20.attn.masked_bias', 'gpt2.transformer.h.22.mlp.c_proj.bias', 'gpt2.transformer.h.2.ln_1.weight', 'prefix_encoder.embedding.weight', 'gpt2.transformer.h.20.attn.c_attn.bias', 'gpt2.transformer.h.2.attn.bias', 'gpt2.transformer.h.11.attn.c_proj.weight', 'gpt2.transformer.h.1.mlp.c_proj.weight', 'gpt2.transformer.h.14.ln_2.bias', 'gpt2.transformer.h.13.ln_1.weight', 'gpt2.transformer.h.4.attn.c_attn.weight', 'gpt2.transformer.h.4.ln_1.bias', 'gpt2.transformer.h.7.ln_2.bias', 'gpt2.transformer.h.3.attn.c_attn.weight', 'gpt2.transformer.h.6.ln_2.bias', 'gpt2.transformer.h.0.ln_1.weight', 'gpt2.transformer.h.23.ln_1.weight', 'gpt2.transformer.h.6.mlp.c_proj.bias', 'gpt2.transformer.h.4.mlp.c_fc.weight', 'gpt2.transformer.h.5.attn.c_proj.weight', 'gpt2.transformer.h.23.attn.c_proj.weight', 'gpt2.transformer.h.12.attn.c_proj.bias', 'classifier.weight', 'gpt2.transformer.h.19.ln_1.weight', 'gpt2.transformer.h.21.attn.c_proj.bias', 'gpt2.transformer.h.12.mlp.c_fc.weight', 'gpt2.transformer.h.14.ln_1.bias', 'gpt2.transformer.h.17.attn.c_attn.bias', 'gpt2.transformer.h.19.mlp.c_proj.weight', 'gpt2.transformer.h.6.ln_2.weight', 'gpt2.transformer.h.18.attn.masked_bias', 'gpt2.transformer.h.2.attn.masked_bias', 'gpt2.transformer.h.19.attn.c_proj.bias', 'gpt2.transformer.h.13.mlp.c_fc.bias', 'gpt2.transformer.h.15.mlp.c_fc.bias', 'gpt2.transformer.h.1.ln_1.bias', 'gpt2.transformer.h.14.attn.masked_bias', 'gpt2.transformer.h.22.attn.c_proj.bias', 'gpt2.transformer.h.3.attn.c_proj.bias', 'gpt2.transformer.h.23.mlp.c_fc.weight', 'gpt2.transformer.h.19.mlp.c_fc.bias', 'gpt2.transformer.h.7.attn.c_proj.bias', 'gpt2.transformer.h.2.attn.c_attn.weight', 'gpt2.transformer.h.13.attn.bias', 'gpt2.transformer.h.7.mlp.c_proj.weight', 'gpt2.transformer.h.9.ln_2.weight', 'gpt2.transformer.h.11.ln_1.weight', 'gpt2.transformer.h.12.mlp.c_proj.bias', 'gpt2.transformer.h.17.mlp.c_fc.weight', 'gpt2.transformer.h.11.mlp.c_fc.bias', 'gpt2.transformer.h.11.mlp.c_proj.bias', 'gpt2.transformer.h.21.mlp.c_fc.bias', 'gpt2.transformer.h.21.mlp.c_proj.weight', 'gpt2.transformer.h.3.attn.c_proj.weight', 'gpt2.transformer.h.14.attn.c_attn.bias', 'gpt2.transformer.h.18.mlp.c_fc.bias', 'gpt2.transformer.h.15.ln_1.weight', 'gpt2.transformer.h.5.mlp.c_proj.bias', 'gpt2.transformer.h.20.ln_2.bias', 'gpt2.transformer.h.16.mlp.c_fc.weight', 'gpt2.transformer.h.9.attn.c_proj.weight', 'gpt2.transformer.h.3.mlp.c_proj.bias', 'gpt2.transformer.h.19.ln_2.bias', 'gpt2.transformer.h.13.ln_2.weight', 'gpt2.transformer.h.6.mlp.c_fc.weight', 'gpt2.transformer.h.23.attn.c_attn.bias', 'gpt2.transformer.h.10.attn.masked_bias', 'gpt2.transformer.h.21.ln_2.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
[INFO|trainer.py:540] 2022-04-19 01:28:34,171 >> The following columns in the training set  don't have a corresponding argument in `GPT2BasePrefixForSequenceClassification.forward` and have been ignored: hypothesis, idx, premise.
[INFO|trainer.py:1196] 2022-04-19 01:28:34,191 >> ***** Running training *****
[INFO|trainer.py:1197] 2022-04-19 01:28:34,191 >>   Num examples = 2490
[INFO|trainer.py:1198] 2022-04-19 01:28:34,191 >>   Num Epochs = 100
[INFO|trainer.py:1199] 2022-04-19 01:28:34,191 >>   Instantaneous batch size per device = 32
[INFO|trainer.py:1200] 2022-04-19 01:28:34,191 >>   Total train batch size (w. parallel, distributed & accumulation) = 32
[INFO|trainer.py:1201] 2022-04-19 01:28:34,191 >>   Gradient Accumulation steps = 1
[INFO|trainer.py:1202] 2022-04-19 01:28:34,191 >>   Total optimization steps = 7800
  0%|          | 0/7800 [00:00<?, ?it/s]Traceback (most recent call last):
  File "run.py", line 139, in <module>
    train(trainer, training_args.resume_from_checkpoint, last_checkpoint)
  File "run.py", line 26, in train
    train_result = trainer.train(resume_from_checkpoint=checkpoint)
  File "/home/ask9126/.conda/envs/pt2/lib/python3.8/site-packages/transformers/trainer.py", line 1316, in train
    tr_loss_step = self.training_step(model, inputs)
  File "/home/ask9126/.conda/envs/pt2/lib/python3.8/site-packages/transformers/trainer.py", line 1849, in training_step
    loss = self.compute_loss(model, inputs)
  File "/home/ask9126/.conda/envs/pt2/lib/python3.8/site-packages/transformers/trainer.py", line 1881, in compute_loss
    outputs = model(**inputs)
  File "/home/ask9126/.conda/envs/pt2/lib/python3.8/site-packages/torch/nn/modules/module.py", line 727, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/scratch/ask9126/soft_prompt_benchmark/P-tuning-v2/model/sequence_classification.py", line 853, in forward
    outputs = self.gpt2(
  File "/home/ask9126/.conda/envs/pt2/lib/python3.8/site-packages/torch/nn/modules/module.py", line 727, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/ask9126/.conda/envs/pt2/lib/python3.8/site-packages/transformers/models/gpt2/modeling_gpt2.py", line 1281, in forward
    transformer_outputs = self.transformer(
  File "/home/ask9126/.conda/envs/pt2/lib/python3.8/site-packages/torch/nn/modules/module.py", line 727, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/ask9126/.conda/envs/pt2/lib/python3.8/site-packages/transformers/models/gpt2/modeling_gpt2.py", line 798, in forward
    outputs = block(
  File "/home/ask9126/.conda/envs/pt2/lib/python3.8/site-packages/torch/nn/modules/module.py", line 727, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/ask9126/.conda/envs/pt2/lib/python3.8/site-packages/transformers/models/gpt2/modeling_gpt2.py", line 318, in forward
    attn_outputs = self.attn(
  File "/home/ask9126/.conda/envs/pt2/lib/python3.8/site-packages/torch/nn/modules/module.py", line 727, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/ask9126/.conda/envs/pt2/lib/python3.8/site-packages/transformers/models/gpt2/modeling_gpt2.py", line 259, in forward
    attn_output, attn_weights = self._attn(query, key, value, attention_mask, head_mask)
  File "/home/ask9126/.conda/envs/pt2/lib/python3.8/site-packages/transformers/models/gpt2/modeling_gpt2.py", line 195, in _attn
    attn_weights = self.attn_dropout(attn_weights)
  File "/home/ask9126/.conda/envs/pt2/lib/python3.8/site-packages/torch/nn/modules/module.py", line 727, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/ask9126/.conda/envs/pt2/lib/python3.8/site-packages/torch/nn/modules/dropout.py", line 58, in forward
    return F.dropout(input, self.p, self.training, self.inplace)
  File "/home/ask9126/.conda/envs/pt2/lib/python3.8/site-packages/torch/nn/functional.py", line 983, in dropout
    else _VF.dropout(input, p, training))
RuntimeError: CUDA out of memory. Tried to allocate 64.00 MiB (GPU 0; 15.78 GiB total capacity; 14.65 GiB already allocated; 20.75 MiB free; 14.65 GiB reserved in total by PyTorch)
  0%|          | 0/7800 [00:02<?, ?it/s]