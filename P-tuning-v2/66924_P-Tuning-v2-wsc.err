
CondaSystemExit: Exiting.



==> WARNING: A newer version of conda exists. <==
  current version: 4.11.0
  latest version: 4.12.0

Please update conda by running

    $ conda update -n base -c defaults conda


Using the `WAND_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).
[INFO|tokenization_auto.py:334] 2022-04-17 21:25:34,316 >> Could not locate the tokenizer configuration file, will try to use the model config instead.
[INFO|configuration_utils.py:583] 2022-04-17 21:25:34,447 >> loading configuration file https://huggingface.co/roberta-large/resolve/main/config.json from cache at /home/ask9126/.cache/huggingface/transformers/dea67b44b38d504f2523f3ddb6acb601b23d67bee52c942da336fa1283100990.94cae8b3a8dbab1d59b9d4827f7ce79e73124efa6bb970412cd503383a95f373
[INFO|configuration_utils.py:620] 2022-04-17 21:25:34,448 >> Model config RobertaConfig {
  "architectures": [
    "RobertaForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "bos_token_id": 0,
  "classifier_dropout": null,
  "eos_token_id": 2,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 1024,
  "initializer_range": 0.02,
  "intermediate_size": 4096,
  "layer_norm_eps": 1e-05,
  "max_position_embeddings": 514,
  "model_type": "roberta",
  "num_attention_heads": 16,
  "num_hidden_layers": 24,
  "pad_token_id": 1,
  "position_embedding_type": "absolute",
  "transformers_version": "4.11.3",
  "type_vocab_size": 1,
  "use_cache": true,
  "vocab_size": 50265
}

[INFO|tokenization_utils_base.py:1741] 2022-04-17 21:25:35,389 >> loading file https://huggingface.co/roberta-large/resolve/main/vocab.json from cache at /home/ask9126/.cache/huggingface/transformers/7c1ba2435b05451bc3b4da073c8dec9630b22024a65f6c41053caccf2880eb8f.d67d6b367eb24ab43b08ad55e014cf254076934f71d832bbab9ad35644a375ab
[INFO|tokenization_utils_base.py:1741] 2022-04-17 21:25:35,389 >> loading file https://huggingface.co/roberta-large/resolve/main/merges.txt from cache at /home/ask9126/.cache/huggingface/transformers/20b5a00a80e27ae9accbe25672aba42ad2d4d4cb2c4b9359b50ca8e34e107d6d.5d12962c5ee615a4c803841266e9c3be9a691a924f72d395d3a6c6c81157788b
[INFO|tokenization_utils_base.py:1741] 2022-04-17 21:25:35,389 >> loading file https://huggingface.co/roberta-large/resolve/main/tokenizer.json from cache at /home/ask9126/.cache/huggingface/transformers/e16a2590deb9e6d73711d6e05bf27d832fa8c1162d807222e043ca650a556964.fc9576039592f026ad76a1c231b89aee8668488c671dfbe6616bab2ed298d730
[INFO|tokenization_utils_base.py:1741] 2022-04-17 21:25:35,389 >> loading file https://huggingface.co/roberta-large/resolve/main/added_tokens.json from cache at None
[INFO|tokenization_utils_base.py:1741] 2022-04-17 21:25:35,389 >> loading file https://huggingface.co/roberta-large/resolve/main/special_tokens_map.json from cache at None
[INFO|tokenization_utils_base.py:1741] 2022-04-17 21:25:35,389 >> loading file https://huggingface.co/roberta-large/resolve/main/tokenizer_config.json from cache at None
[INFO|configuration_utils.py:583] 2022-04-17 21:25:35,514 >> loading configuration file https://huggingface.co/roberta-large/resolve/main/config.json from cache at /home/ask9126/.cache/huggingface/transformers/dea67b44b38d504f2523f3ddb6acb601b23d67bee52c942da336fa1283100990.94cae8b3a8dbab1d59b9d4827f7ce79e73124efa6bb970412cd503383a95f373
[INFO|configuration_utils.py:620] 2022-04-17 21:25:35,515 >> Model config RobertaConfig {
  "architectures": [
    "RobertaForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "bos_token_id": 0,
  "classifier_dropout": null,
  "eos_token_id": 2,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 1024,
  "initializer_range": 0.02,
  "intermediate_size": 4096,
  "layer_norm_eps": 1e-05,
  "max_position_embeddings": 514,
  "model_type": "roberta",
  "num_attention_heads": 16,
  "num_hidden_layers": 24,
  "pad_token_id": 1,
  "position_embedding_type": "absolute",
  "transformers_version": "4.11.3",
  "type_vocab_size": 1,
  "use_cache": true,
  "vocab_size": 50265
}

Downloading:   0%|          | 0.00/32.8k [00:00<?, ?B/s]Downloading: 100%|██████████| 32.8k/32.8k [00:00<00:00, 465kB/s]
0 examples [00:00, ? examples/s]                                0 examples [00:00, ? examples/s]                                0 examples [00:00, ? examples/s]                                  0%|          | 0/3 [00:00<?, ?it/s]100%|██████████| 3/3 [00:00<00:00, 165.45it/s]
Running tokenizer on dataset:   0%|          | 0/1 [00:00<?, ?ba/s]Running tokenizer on dataset: 100%|██████████| 1/1 [00:00<00:00, 15.02ba/s]
Running tokenizer on dataset:   0%|          | 0/1 [00:00<?, ?ba/s]Running tokenizer on dataset: 100%|██████████| 1/1 [00:00<00:00, 69.96ba/s]
Running tokenizer on dataset:   0%|          | 0/1 [00:00<?, ?ba/s]Running tokenizer on dataset: 100%|██████████| 1/1 [00:00<00:00, 61.92ba/s]
[INFO|configuration_utils.py:583] 2022-04-17 21:25:38,565 >> loading configuration file https://huggingface.co/roberta-large/resolve/main/config.json from cache at /home/ask9126/.cache/huggingface/transformers/dea67b44b38d504f2523f3ddb6acb601b23d67bee52c942da336fa1283100990.94cae8b3a8dbab1d59b9d4827f7ce79e73124efa6bb970412cd503383a95f373
[INFO|configuration_utils.py:620] 2022-04-17 21:25:38,565 >> Model config RobertaConfig {
  "architectures": [
    "RobertaForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "bos_token_id": 0,
  "classifier_dropout": null,
  "eos_token_id": 2,
  "finetuning_task": "wsc",
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 1024,
  "id2label": {
    "0": "False",
    "1": "True"
  },
  "initializer_range": 0.02,
  "intermediate_size": 4096,
  "label2id": {
    "False": 0,
    "True": 1
  },
  "layer_norm_eps": 1e-05,
  "max_position_embeddings": 514,
  "model_type": "roberta",
  "num_attention_heads": 16,
  "num_hidden_layers": 24,
  "pad_token_id": 1,
  "position_embedding_type": "absolute",
  "transformers_version": "4.11.3",
  "type_vocab_size": 1,
  "use_cache": true,
  "vocab_size": 50265
}

[INFO|modeling_utils.py:1323] 2022-04-17 21:25:38,697 >> loading weights file https://huggingface.co/roberta-large/resolve/main/pytorch_model.bin from cache at /home/ask9126/.cache/huggingface/transformers/8e36ec2f5052bec1e79e139b84c2c3089cb647694ba0f4f634fec7b8258f7c89.c43841d8c5cd23c435408295164cda9525270aa42cd0cc9200911570c0342352
[WARNING|modeling_utils.py:1579] 2022-04-17 21:25:51,934 >> Some weights of the model checkpoint at roberta-large were not used when initializing RobertaPrefixForSequenceClassification: ['lm_head.dense.bias', 'lm_head.decoder.weight', 'lm_head.layer_norm.weight', 'lm_head.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias']
- This IS expected if you are initializing RobertaPrefixForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing RobertaPrefixForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
[WARNING|modeling_utils.py:1590] 2022-04-17 21:25:51,934 >> Some weights of RobertaPrefixForSequenceClassification were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.embeddings.position_ids', 'prefix_encoder.embedding.weight', 'classifier.weight', 'classifier.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
[INFO|trainer.py:540] 2022-04-17 21:26:01,487 >> The following columns in the training set  don't have a corresponding argument in `RobertaPrefixForSequenceClassification.forward` and have been ignored: idx, span2_text, text, span1_index, span2_index, span1_text, span2_word_text.
[INFO|trainer.py:1196] 2022-04-17 21:26:01,514 >> ***** Running training *****
[INFO|trainer.py:1197] 2022-04-17 21:26:01,514 >>   Num examples = 554
[INFO|trainer.py:1198] 2022-04-17 21:26:01,514 >>   Num Epochs = 10
[INFO|trainer.py:1199] 2022-04-17 21:26:01,514 >>   Instantaneous batch size per device = 16
[INFO|trainer.py:1200] 2022-04-17 21:26:01,514 >>   Total train batch size (w. parallel, distributed & accumulation) = 16
[INFO|trainer.py:1201] 2022-04-17 21:26:01,514 >>   Gradient Accumulation steps = 1
[INFO|trainer.py:1202] 2022-04-17 21:26:01,514 >>   Total optimization steps = 350
  0%|          | 0/350 [00:00<?, ?it/s]  0%|          | 1/350 [00:02<14:13,  2.45s/it]  1%|          | 2/350 [00:02<06:42,  1.16s/it]  1%|          | 3/350 [00:02<04:18,  1.34it/s]  1%|          | 4/350 [00:03<03:10,  1.82it/s]  1%|▏         | 5/350 [00:03<02:32,  2.26it/s]  2%|▏         | 6/350 [00:03<02:10,  2.64it/s]  2%|▏         | 7/350 [00:03<01:55,  2.97it/s]  2%|▏         | 8/350 [00:04<01:46,  3.22it/s]  3%|▎         | 9/350 [00:04<01:39,  3.42it/s]  3%|▎         | 10/350 [00:04<01:35,  3.57it/s]  3%|▎         | 11/350 [00:04<01:32,  3.68it/s]  3%|▎         | 12/350 [00:05<01:29,  3.76it/s]  4%|▎         | 13/350 [00:05<01:28,  3.82it/s]  4%|▍         | 14/350 [00:05<01:27,  3.85it/s]  4%|▍         | 15/350 [00:05<01:26,  3.88it/s]  5%|▍         | 16/350 [00:06<01:25,  3.89it/s]  5%|▍         | 17/350 [00:06<01:25,  3.91it/s]  5%|▌         | 18/350 [00:06<01:24,  3.91it/s]  5%|▌         | 19/350 [00:07<01:24,  3.92it/s]  6%|▌         | 20/350 [00:07<01:24,  3.92it/s]  6%|▌         | 21/350 [00:07<01:23,  3.93it/s]  6%|▋         | 22/350 [00:07<01:23,  3.92it/s]  7%|▋         | 23/350 [00:08<01:23,  3.93it/s]  7%|▋         | 24/350 [00:08<01:22,  3.94it/s]  7%|▋         | 25/350 [00:08<01:22,  3.94it/s]  7%|▋         | 26/350 [00:08<01:22,  3.94it/s]  8%|▊         | 27/350 [00:09<01:22,  3.93it/s]  8%|▊         | 28/350 [00:09<01:21,  3.93it/s]  8%|▊         | 29/350 [00:09<01:21,  3.93it/s]  9%|▊         | 30/350 [00:09<01:21,  3.93it/s]  9%|▉         | 31/350 [00:10<01:21,  3.93it/s]  9%|▉         | 32/350 [00:10<01:20,  3.93it/s]  9%|▉         | 33/350 [00:10<01:20,  3.93it/s] 10%|▉         | 34/350 [00:10<01:20,  3.93it/s] 10%|█         | 35/350 [00:10<01:10,  4.46it/s][INFO|trainer.py:540] 2022-04-17 21:26:12,492 >> The following columns in the evaluation set  don't have a corresponding argument in `RobertaPrefixForSequenceClassification.forward` and have been ignored: idx, span2_text, text, span1_index, span2_index, span1_text, span2_word_text.
[INFO|trainer.py:2243] 2022-04-17 21:26:12,494 >> ***** Running Evaluation *****
[INFO|trainer.py:2245] 2022-04-17 21:26:12,494 >>   Num examples = 104
[INFO|trainer.py:2248] 2022-04-17 21:26:12,494 >>   Batch size = 8

  0%|          | 0/13 [00:00<?, ?it/s][A
 23%|██▎       | 3/13 [00:00<00:00, 23.08it/s][A
 46%|████▌     | 6/13 [00:00<00:00, 17.81it/s][A
 62%|██████▏   | 8/13 [00:00<00:00, 16.83it/s][A
 77%|███████▋  | 10/13 [00:00<00:00, 16.31it/s][A
 92%|█████████▏| 12/13 [00:00<00:00, 15.95it/s][A                                                
                                               [A 10%|█         | 35/350 [00:11<01:10,  4.46it/s]
100%|██████████| 13/13 [00:00<00:00, 15.95it/s][A
                                               [A                                                 10%|█         | 35/350 [00:11<01:10,  4.46it/s] 10%|█         | 36/350 [00:12<02:37,  1.99it/s] 11%|█         | 37/350 [00:12<02:14,  2.33it/s] 11%|█         | 38/350 [00:12<01:57,  2.66it/s] 11%|█         | 39/350 [00:12<01:45,  2.94it/s] 11%|█▏        | 40/350 [00:13<01:37,  3.18it/s] 12%|█▏        | 41/350 [00:13<01:31,  3.38it/s] 12%|█▏        | 42/350 [00:13<01:27,  3.53it/s] 12%|█▏        | 43/350 [00:13<01:24,  3.64it/s] 13%|█▎        | 44/350 [00:14<01:21,  3.74it/s] 13%|█▎        | 45/350 [00:14<01:20,  3.79it/s] 13%|█▎        | 46/350 [00:14<01:19,  3.83it/s] 13%|█▎        | 47/350 [00:14<01:18,  3.87it/s] 14%|█▎        | 48/350 [00:15<01:17,  3.89it/s] 14%|█▍        | 49/350 [00:15<01:17,  3.91it/s] 14%|█▍        | 50/350 [00:15<01:16,  3.92it/s] 15%|█▍        | 51/350 [00:15<01:16,  3.93it/s] 15%|█▍        | 52/350 [00:16<01:15,  3.93it/s] 15%|█▌        | 53/350 [00:16<01:15,  3.92it/s] 15%|█▌        | 54/350 [00:16<01:15,  3.92it/s] 16%|█▌        | 55/350 [00:16<01:15,  3.92it/s] 16%|█▌        | 56/350 [00:17<01:14,  3.93it/s] 16%|█▋        | 57/350 [00:17<01:14,  3.93it/s] 17%|█▋        | 58/350 [00:17<01:14,  3.94it/s] 17%|█▋        | 59/350 [00:17<01:13,  3.95it/s] 17%|█▋        | 60/350 [00:18<01:13,  3.94it/s] 17%|█▋        | 61/350 [00:18<01:13,  3.93it/s] 18%|█▊        | 62/350 [00:18<01:13,  3.93it/s] 18%|█▊        | 63/350 [00:18<01:13,  3.92it/s] 18%|█▊        | 64/350 [00:19<01:12,  3.92it/s] 19%|█▊        | 65/350 [00:19<01:12,  3.92it/s] 19%|█▉        | 66/350 [00:19<01:12,  3.93it/s] 19%|█▉        | 67/350 [00:20<01:12,  3.93it/s] 19%|█▉        | 68/350 [00:20<01:11,  3.93it/s] 20%|█▉        | 69/350 [00:20<01:11,  3.91it/s] 20%|██        | 70/350 [00:20<01:02,  4.45it/s][INFO|trainer.py:540] 2022-04-17 21:26:22,190 >> The following columns in the evaluation set  don't have a corresponding argument in `RobertaPrefixForSequenceClassification.forward` and have been ignored: idx, span2_text, text, span1_index, span2_index, span1_text, span2_word_text.
[INFO|trainer.py:2243] 2022-04-17 21:26:22,192 >> ***** Running Evaluation *****
[INFO|trainer.py:2245] 2022-04-17 21:26:22,192 >>   Num examples = 104
[INFO|trainer.py:2248] 2022-04-17 21:26:22,192 >>   Batch size = 8

  0%|          | 0/13 [00:00<?, ?it/s][A
 23%|██▎       | 3/13 [00:00<00:00, 23.08it/s][A
 46%|████▌     | 6/13 [00:00<00:00, 17.74it/s][A
 62%|██████▏   | 8/13 [00:00<00:00, 16.76it/s][A
 77%|███████▋  | 10/13 [00:00<00:00, 16.21it/s][A
 92%|█████████▏| 12/13 [00:00<00:00, 15.91it/s][A                                                
                                               [A 20%|██        | 70/350 [00:21<01:02,  4.45it/s]
100%|██████████| 13/13 [00:00<00:00, 15.91it/s][A
                                               [A                                                 20%|██        | 70/350 [00:21<01:02,  4.45it/s] 20%|██        | 71/350 [00:21<02:18,  2.01it/s] 21%|██        | 72/350 [00:22<01:58,  2.36it/s] 21%|██        | 73/350 [00:22<01:43,  2.68it/s] 21%|██        | 74/350 [00:22<01:33,  2.96it/s] 21%|██▏       | 75/350 [00:22<01:26,  3.19it/s] 22%|██▏       | 76/350 [00:23<01:21,  3.37it/s] 22%|██▏       | 77/350 [00:23<01:17,  3.51it/s] 22%|██▏       | 78/350 [00:23<01:14,  3.63it/s] 23%|██▎       | 79/350 [00:23<01:13,  3.71it/s] 23%|██▎       | 80/350 [00:24<01:11,  3.77it/s] 23%|██▎       | 81/350 [00:24<01:10,  3.81it/s] 23%|██▎       | 82/350 [00:24<01:09,  3.84it/s] 24%|██▎       | 83/350 [00:24<01:09,  3.87it/s] 24%|██▍       | 84/350 [00:25<01:08,  3.88it/s] 24%|██▍       | 85/350 [00:25<01:08,  3.89it/s] 25%|██▍       | 86/350 [00:25<01:07,  3.91it/s] 25%|██▍       | 87/350 [00:25<01:07,  3.91it/s] 25%|██▌       | 88/350 [00:26<01:07,  3.91it/s] 25%|██▌       | 89/350 [00:26<01:06,  3.91it/s] 26%|██▌       | 90/350 [00:26<01:06,  3.91it/s] 26%|██▌       | 91/350 [00:26<01:06,  3.92it/s] 26%|██▋       | 92/350 [00:27<01:05,  3.92it/s] 27%|██▋       | 93/350 [00:27<01:05,  3.93it/s] 27%|██▋       | 94/350 [00:27<01:05,  3.92it/s] 27%|██▋       | 95/350 [00:27<01:04,  3.93it/s] 27%|██▋       | 96/350 [00:28<01:04,  3.93it/s] 28%|██▊       | 97/350 [00:28<01:04,  3.94it/s] 28%|██▊       | 98/350 [00:28<01:04,  3.93it/s] 28%|██▊       | 99/350 [00:28<01:03,  3.93it/s] 29%|██▊       | 100/350 [00:29<01:03,  3.93it/s] 29%|██▉       | 101/350 [00:29<01:03,  3.93it/s] 29%|██▉       | 102/350 [00:29<01:02,  3.94it/s] 29%|██▉       | 103/350 [00:29<01:02,  3.93it/s] 30%|██▉       | 104/350 [00:30<01:02,  3.93it/s] 30%|███       | 105/350 [00:30<00:54,  4.46it/s][INFO|trainer.py:540] 2022-04-17 21:26:31,890 >> The following columns in the evaluation set  don't have a corresponding argument in `RobertaPrefixForSequenceClassification.forward` and have been ignored: idx, span2_text, text, span1_index, span2_index, span1_text, span2_word_text.
[INFO|trainer.py:2243] 2022-04-17 21:26:31,892 >> ***** Running Evaluation *****
[INFO|trainer.py:2245] 2022-04-17 21:26:31,892 >>   Num examples = 104
[INFO|trainer.py:2248] 2022-04-17 21:26:31,892 >>   Batch size = 8

  0%|          | 0/13 [00:00<?, ?it/s][A
 23%|██▎       | 3/13 [00:00<00:00, 22.96it/s][A
 46%|████▌     | 6/13 [00:00<00:00, 17.72it/s][A
 62%|██████▏   | 8/13 [00:00<00:00, 16.71it/s][A
 77%|███████▋  | 10/13 [00:00<00:00, 16.19it/s][A
 92%|█████████▏| 12/13 [00:00<00:00, 15.88it/s][A                                                 
                                               [A 30%|███       | 105/350 [00:31<00:54,  4.46it/s]
100%|██████████| 13/13 [00:00<00:00, 15.88it/s][A
                                               [A                                                  30%|███       | 105/350 [00:31<00:54,  4.46it/s] 30%|███       | 106/350 [00:31<02:01,  2.00it/s] 31%|███       | 107/350 [00:31<01:43,  2.35it/s] 31%|███       | 108/350 [00:32<01:30,  2.67it/s] 31%|███       | 109/350 [00:32<01:21,  2.95it/s] 31%|███▏      | 110/350 [00:32<01:15,  3.18it/s] 32%|███▏      | 111/350 [00:32<01:10,  3.37it/s] 32%|███▏      | 112/350 [00:33<01:07,  3.52it/s] 32%|███▏      | 113/350 [00:33<01:05,  3.63it/s] 33%|███▎      | 114/350 [00:33<01:03,  3.71it/s] 33%|███▎      | 115/350 [00:33<01:02,  3.78it/s] 33%|███▎      | 116/350 [00:34<01:01,  3.82it/s] 33%|███▎      | 117/350 [00:34<01:00,  3.86it/s] 34%|███▎      | 118/350 [00:34<00:59,  3.88it/s] 34%|███▍      | 119/350 [00:34<00:59,  3.90it/s] 34%|███▍      | 120/350 [00:35<00:58,  3.90it/s] 35%|███▍      | 121/350 [00:35<00:58,  3.91it/s] 35%|███▍      | 122/350 [00:35<00:58,  3.90it/s] 35%|███▌      | 123/350 [00:35<00:57,  3.92it/s] 35%|███▌      | 124/350 [00:36<00:57,  3.92it/s] 36%|███▌      | 125/350 [00:36<00:57,  3.92it/s] 36%|███▌      | 126/350 [00:36<00:57,  3.93it/s] 36%|███▋      | 127/350 [00:36<00:56,  3.93it/s] 37%|███▋      | 128/350 [00:37<00:56,  3.93it/s] 37%|███▋      | 129/350 [00:37<00:56,  3.93it/s] 37%|███▋      | 130/350 [00:37<00:56,  3.93it/s] 37%|███▋      | 131/350 [00:37<00:55,  3.92it/s] 38%|███▊      | 132/350 [00:38<00:55,  3.92it/s] 38%|███▊      | 133/350 [00:38<00:55,  3.92it/s] 38%|███▊      | 134/350 [00:38<00:55,  3.92it/s] 39%|███▊      | 135/350 [00:38<00:54,  3.92it/s] 39%|███▉      | 136/350 [00:39<00:54,  3.92it/s] 39%|███▉      | 137/350 [00:39<00:54,  3.91it/s] 39%|███▉      | 138/350 [00:39<00:54,  3.91it/s] 40%|███▉      | 139/350 [00:39<00:53,  3.91it/s] 40%|████      | 140/350 [00:40<00:47,  4.45it/s][INFO|trainer.py:540] 2022-04-17 21:26:41,598 >> The following columns in the evaluation set  don't have a corresponding argument in `RobertaPrefixForSequenceClassification.forward` and have been ignored: idx, span2_text, text, span1_index, span2_index, span1_text, span2_word_text.
[INFO|trainer.py:2243] 2022-04-17 21:26:41,600 >> ***** Running Evaluation *****
[INFO|trainer.py:2245] 2022-04-17 21:26:41,600 >>   Num examples = 104
[INFO|trainer.py:2248] 2022-04-17 21:26:41,600 >>   Batch size = 8

  0%|          | 0/13 [00:00<?, ?it/s][A
 23%|██▎       | 3/13 [00:00<00:00, 23.13it/s][A
 46%|████▌     | 6/13 [00:00<00:00, 17.78it/s][A
 62%|██████▏   | 8/13 [00:00<00:00, 16.74it/s][A
 77%|███████▋  | 10/13 [00:00<00:00, 16.21it/s][A
 92%|█████████▏| 12/13 [00:00<00:00, 15.87it/s][A                                                 
                                               [A 40%|████      | 140/350 [00:40<00:47,  4.45it/s]
100%|██████████| 13/13 [00:00<00:00, 15.87it/s][A
                                               [A                                                  40%|████      | 140/350 [00:40<00:47,  4.45it/s] 40%|████      | 141/350 [00:41<01:45,  1.99it/s] 41%|████      | 142/350 [00:41<01:29,  2.33it/s] 41%|████      | 143/350 [00:41<01:18,  2.65it/s] 41%|████      | 144/350 [00:41<01:10,  2.94it/s] 41%|████▏     | 145/350 [00:42<01:04,  3.17it/s] 42%|████▏     | 146/350 [00:42<01:00,  3.37it/s] 42%|████▏     | 147/350 [00:42<00:57,  3.52it/s] 42%|████▏     | 148/350 [00:43<00:55,  3.63it/s] 43%|████▎     | 149/350 [00:43<00:54,  3.71it/s] 43%|████▎     | 150/350 [00:43<00:52,  3.78it/s] 43%|████▎     | 151/350 [00:43<00:52,  3.82it/s] 43%|████▎     | 152/350 [00:44<00:51,  3.85it/s] 44%|████▎     | 153/350 [00:44<00:50,  3.87it/s] 44%|████▍     | 154/350 [00:44<00:50,  3.88it/s] 44%|████▍     | 155/350 [00:44<00:50,  3.88it/s] 45%|████▍     | 156/350 [00:45<00:49,  3.89it/s] 45%|████▍     | 157/350 [00:45<00:49,  3.90it/s] 45%|████▌     | 158/350 [00:45<00:49,  3.91it/s] 45%|████▌     | 159/350 [00:45<00:48,  3.91it/s] 46%|████▌     | 160/350 [00:46<00:48,  3.91it/s] 46%|████▌     | 161/350 [00:46<00:48,  3.91it/s] 46%|████▋     | 162/350 [00:46<00:48,  3.91it/s] 47%|████▋     | 163/350 [00:46<00:47,  3.91it/s] 47%|████▋     | 164/350 [00:47<00:47,  3.92it/s] 47%|████▋     | 165/350 [00:47<00:47,  3.91it/s] 47%|████▋     | 166/350 [00:47<00:47,  3.91it/s] 48%|████▊     | 167/350 [00:47<00:46,  3.91it/s] 48%|████▊     | 168/350 [00:48<00:46,  3.91it/s] 48%|████▊     | 169/350 [00:48<00:46,  3.92it/s] 49%|████▊     | 170/350 [00:48<00:45,  3.93it/s] 49%|████▉     | 171/350 [00:48<00:45,  3.93it/s] 49%|████▉     | 172/350 [00:49<00:45,  3.92it/s] 49%|████▉     | 173/350 [00:49<00:45,  3.92it/s] 50%|████▉     | 174/350 [00:49<00:44,  3.92it/s] 50%|█████     | 175/350 [00:49<00:39,  4.45it/s][INFO|trainer.py:540] 2022-04-17 21:26:51,330 >> The following columns in the evaluation set  don't have a corresponding argument in `RobertaPrefixForSequenceClassification.forward` and have been ignored: idx, span2_text, text, span1_index, span2_index, span1_text, span2_word_text.
[INFO|trainer.py:2243] 2022-04-17 21:26:51,332 >> ***** Running Evaluation *****
[INFO|trainer.py:2245] 2022-04-17 21:26:51,332 >>   Num examples = 104
[INFO|trainer.py:2248] 2022-04-17 21:26:51,332 >>   Batch size = 8

  0%|          | 0/13 [00:00<?, ?it/s][A
 23%|██▎       | 3/13 [00:00<00:00, 22.90it/s][A
 46%|████▌     | 6/13 [00:00<00:00, 17.57it/s][A
 62%|██████▏   | 8/13 [00:00<00:00, 16.63it/s][A
 77%|███████▋  | 10/13 [00:00<00:00, 16.08it/s][A
 92%|█████████▏| 12/13 [00:00<00:00, 15.75it/s][A                                                 
                                               [A 50%|█████     | 175/350 [00:50<00:39,  4.45it/s]
100%|██████████| 13/13 [00:00<00:00, 15.75it/s][A
                                               [A                                                  50%|█████     | 175/350 [00:50<00:39,  4.45it/s] 50%|█████     | 176/350 [00:50<01:27,  1.99it/s] 51%|█████     | 177/350 [00:51<01:14,  2.34it/s] 51%|█████     | 178/350 [00:51<01:04,  2.66it/s] 51%|█████     | 179/350 [00:51<00:58,  2.93it/s] 51%|█████▏    | 180/350 [00:51<00:53,  3.17it/s] 52%|█████▏    | 181/350 [00:52<00:50,  3.37it/s] 52%|█████▏    | 182/350 [00:52<00:47,  3.51it/s] 52%|█████▏    | 183/350 [00:52<00:46,  3.62it/s] 53%|█████▎    | 184/350 [00:53<00:44,  3.70it/s] 53%|█████▎    | 185/350 [00:53<00:43,  3.77it/s] 53%|█████▎    | 186/350 [00:53<00:42,  3.81it/s] 53%|█████▎    | 187/350 [00:53<00:42,  3.85it/s] 54%|█████▎    | 188/350 [00:54<00:41,  3.87it/s] 54%|█████▍    | 189/350 [00:54<00:41,  3.88it/s] 54%|█████▍    | 190/350 [00:54<00:41,  3.89it/s] 55%|█████▍    | 191/350 [00:54<00:40,  3.90it/s] 55%|█████▍    | 192/350 [00:55<00:40,  3.90it/s] 55%|█████▌    | 193/350 [00:55<00:40,  3.90it/s] 55%|█████▌    | 194/350 [00:55<00:40,  3.90it/s] 56%|█████▌    | 195/350 [00:55<00:39,  3.89it/s] 56%|█████▌    | 196/350 [00:56<00:39,  3.90it/s] 56%|█████▋    | 197/350 [00:56<00:39,  3.90it/s] 57%|█████▋    | 198/350 [00:56<00:38,  3.91it/s] 57%|█████▋    | 199/350 [00:56<00:38,  3.91it/s] 57%|█████▋    | 200/350 [00:57<00:38,  3.91it/s] 57%|█████▋    | 201/350 [00:57<00:38,  3.90it/s] 58%|█████▊    | 202/350 [00:57<00:37,  3.91it/s] 58%|█████▊    | 203/350 [00:57<00:37,  3.90it/s] 58%|█████▊    | 204/350 [00:58<00:37,  3.91it/s] 59%|█████▊    | 205/350 [00:58<00:37,  3.91it/s] 59%|█████▉    | 206/350 [00:58<00:36,  3.91it/s] 59%|█████▉    | 207/350 [00:58<00:36,  3.90it/s] 59%|█████▉    | 208/350 [00:59<00:36,  3.90it/s] 60%|█████▉    | 209/350 [00:59<00:36,  3.90it/s] 60%|██████    | 210/350 [00:59<00:31,  4.43it/s][INFO|trainer.py:540] 2022-04-17 21:27:01,077 >> The following columns in the evaluation set  don't have a corresponding argument in `RobertaPrefixForSequenceClassification.forward` and have been ignored: idx, span2_text, text, span1_index, span2_index, span1_text, span2_word_text.
[INFO|trainer.py:2243] 2022-04-17 21:27:01,079 >> ***** Running Evaluation *****
[INFO|trainer.py:2245] 2022-04-17 21:27:01,079 >>   Num examples = 104
[INFO|trainer.py:2248] 2022-04-17 21:27:01,079 >>   Batch size = 8

  0%|          | 0/13 [00:00<?, ?it/s][A
 23%|██▎       | 3/13 [00:00<00:00, 22.99it/s][A
 46%|████▌     | 6/13 [00:00<00:00, 17.66it/s][A
 62%|██████▏   | 8/13 [00:00<00:00, 16.66it/s][A
 77%|███████▋  | 10/13 [00:00<00:00, 16.11it/s][A
 92%|█████████▏| 12/13 [00:00<00:00, 15.82it/s][A                                                 
                                               [A 60%|██████    | 210/350 [01:00<00:31,  4.43it/s]
100%|██████████| 13/13 [00:00<00:00, 15.82it/s][A
                                               [A                                                  60%|██████    | 210/350 [01:00<00:31,  4.43it/s] 60%|██████    | 211/350 [01:00<01:09,  1.99it/s] 61%|██████    | 212/350 [01:00<00:59,  2.33it/s] 61%|██████    | 213/350 [01:01<00:51,  2.65it/s] 61%|██████    | 214/350 [01:01<00:46,  2.94it/s] 61%|██████▏   | 215/350 [01:01<00:42,  3.17it/s] 62%|██████▏   | 216/350 [01:01<00:39,  3.37it/s] 62%|██████▏   | 217/350 [01:02<00:37,  3.51it/s] 62%|██████▏   | 218/350 [01:02<00:36,  3.61it/s] 63%|██████▎   | 219/350 [01:02<00:35,  3.69it/s] 63%|██████▎   | 220/350 [01:03<00:34,  3.76it/s] 63%|██████▎   | 221/350 [01:03<00:33,  3.81it/s] 63%|██████▎   | 222/350 [01:03<00:33,  3.83it/s] 64%|██████▎   | 223/350 [01:03<00:32,  3.86it/s] 64%|██████▍   | 224/350 [01:04<00:32,  3.89it/s] 64%|██████▍   | 225/350 [01:04<00:32,  3.89it/s] 65%|██████▍   | 226/350 [01:04<00:31,  3.90it/s] 65%|██████▍   | 227/350 [01:04<00:31,  3.90it/s] 65%|██████▌   | 228/350 [01:05<00:31,  3.91it/s] 65%|██████▌   | 229/350 [01:05<00:31,  3.90it/s] 66%|██████▌   | 230/350 [01:05<00:30,  3.91it/s] 66%|██████▌   | 231/350 [01:05<00:30,  3.91it/s] 66%|██████▋   | 232/350 [01:06<00:30,  3.91it/s] 67%|██████▋   | 233/350 [01:06<00:29,  3.91it/s] 67%|██████▋   | 234/350 [01:06<00:29,  3.91it/s] 67%|██████▋   | 235/350 [01:06<00:29,  3.91it/s] 67%|██████▋   | 236/350 [01:07<00:29,  3.92it/s] 68%|██████▊   | 237/350 [01:07<00:28,  3.91it/s] 68%|██████▊   | 238/350 [01:07<00:28,  3.91it/s] 68%|██████▊   | 239/350 [01:07<00:28,  3.92it/s] 69%|██████▊   | 240/350 [01:08<00:28,  3.92it/s] 69%|██████▉   | 241/350 [01:08<00:27,  3.92it/s] 69%|██████▉   | 242/350 [01:08<00:27,  3.92it/s] 69%|██████▉   | 243/350 [01:08<00:27,  3.93it/s] 70%|██████▉   | 244/350 [01:09<00:27,  3.92it/s] 70%|███████   | 245/350 [01:09<00:23,  4.45it/s][INFO|trainer.py:540] 2022-04-17 21:27:10,813 >> The following columns in the evaluation set  don't have a corresponding argument in `RobertaPrefixForSequenceClassification.forward` and have been ignored: idx, span2_text, text, span1_index, span2_index, span1_text, span2_word_text.
[INFO|trainer.py:2243] 2022-04-17 21:27:10,815 >> ***** Running Evaluation *****
[INFO|trainer.py:2245] 2022-04-17 21:27:10,815 >>   Num examples = 104
[INFO|trainer.py:2248] 2022-04-17 21:27:10,815 >>   Batch size = 8

  0%|          | 0/13 [00:00<?, ?it/s][A
 23%|██▎       | 3/13 [00:00<00:00, 22.99it/s][A
 46%|████▌     | 6/13 [00:00<00:00, 17.64it/s][A
 62%|██████▏   | 8/13 [00:00<00:00, 16.72it/s][A
 77%|███████▋  | 10/13 [00:00<00:00, 16.11it/s][A
 92%|█████████▏| 12/13 [00:00<00:00, 15.75it/s][A                                                 
                                               [A 70%|███████   | 245/350 [01:10<00:23,  4.45it/s]
100%|██████████| 13/13 [00:00<00:00, 15.75it/s][A
                                               [A                                                  70%|███████   | 245/350 [01:10<00:23,  4.45it/s] 70%|███████   | 246/350 [01:10<00:52,  2.00it/s] 71%|███████   | 247/350 [01:10<00:43,  2.34it/s] 71%|███████   | 248/350 [01:10<00:38,  2.66it/s] 71%|███████   | 249/350 [01:11<00:34,  2.94it/s] 71%|███████▏  | 250/350 [01:11<00:31,  3.18it/s] 72%|███████▏  | 251/350 [01:11<00:29,  3.37it/s] 72%|███████▏  | 252/350 [01:11<00:27,  3.51it/s] 72%|███████▏  | 253/350 [01:12<00:26,  3.63it/s] 73%|███████▎  | 254/350 [01:12<00:25,  3.70it/s] 73%|███████▎  | 255/350 [01:12<00:25,  3.77it/s] 73%|███████▎  | 256/350 [01:12<00:24,  3.81it/s] 73%|███████▎  | 257/350 [01:13<00:24,  3.84it/s] 74%|███████▎  | 258/350 [01:13<00:23,  3.86it/s] 74%|███████▍  | 259/350 [01:13<00:23,  3.88it/s] 74%|███████▍  | 260/350 [01:14<00:23,  3.88it/s] 75%|███████▍  | 261/350 [01:14<00:22,  3.89it/s] 75%|███████▍  | 262/350 [01:14<00:22,  3.90it/s] 75%|███████▌  | 263/350 [01:14<00:22,  3.91it/s] 75%|███████▌  | 264/350 [01:15<00:22,  3.90it/s] 76%|███████▌  | 265/350 [01:15<00:21,  3.90it/s] 76%|███████▌  | 266/350 [01:15<00:21,  3.89it/s] 76%|███████▋  | 267/350 [01:15<00:21,  3.90it/s] 77%|███████▋  | 268/350 [01:16<00:21,  3.90it/s] 77%|███████▋  | 269/350 [01:16<00:20,  3.90it/s] 77%|███████▋  | 270/350 [01:16<00:20,  3.91it/s] 77%|███████▋  | 271/350 [01:16<00:20,  3.90it/s] 78%|███████▊  | 272/350 [01:17<00:19,  3.91it/s] 78%|███████▊  | 273/350 [01:17<00:19,  3.92it/s] 78%|███████▊  | 274/350 [01:17<00:19,  3.92it/s] 79%|███████▊  | 275/350 [01:17<00:19,  3.92it/s] 79%|███████▉  | 276/350 [01:18<00:18,  3.93it/s] 79%|███████▉  | 277/350 [01:18<00:18,  3.92it/s] 79%|███████▉  | 278/350 [01:18<00:18,  3.93it/s] 80%|███████▉  | 279/350 [01:18<00:18,  3.92it/s] 80%|████████  | 280/350 [01:19<00:15,  4.44it/s][INFO|trainer.py:540] 2022-04-17 21:27:20,547 >> The following columns in the evaluation set  don't have a corresponding argument in `RobertaPrefixForSequenceClassification.forward` and have been ignored: idx, span2_text, text, span1_index, span2_index, span1_text, span2_word_text.
[INFO|trainer.py:2243] 2022-04-17 21:27:20,549 >> ***** Running Evaluation *****
[INFO|trainer.py:2245] 2022-04-17 21:27:20,549 >>   Num examples = 104
[INFO|trainer.py:2248] 2022-04-17 21:27:20,549 >>   Batch size = 8

  0%|          | 0/13 [00:00<?, ?it/s][A
 23%|██▎       | 3/13 [00:00<00:00, 22.68it/s][A
 46%|████▌     | 6/13 [00:00<00:00, 17.52it/s][A
 62%|██████▏   | 8/13 [00:00<00:00, 16.59it/s][A
 77%|███████▋  | 10/13 [00:00<00:00, 16.11it/s][A
 92%|█████████▏| 12/13 [00:00<00:00, 15.80it/s][A                                                 
                                               [A 80%|████████  | 280/350 [01:19<00:15,  4.44it/s]
100%|██████████| 13/13 [00:00<00:00, 15.80it/s][A
                                               [A                                                  80%|████████  | 280/350 [01:19<00:15,  4.44it/s] 80%|████████  | 281/350 [01:20<00:34,  1.98it/s] 81%|████████  | 282/350 [01:20<00:29,  2.33it/s] 81%|████████  | 283/350 [01:20<00:25,  2.65it/s] 81%|████████  | 284/350 [01:20<00:22,  2.94it/s] 81%|████████▏ | 285/350 [01:21<00:20,  3.17it/s] 82%|████████▏ | 286/350 [01:21<00:19,  3.36it/s] 82%|████████▏ | 287/350 [01:21<00:17,  3.51it/s] 82%|████████▏ | 288/350 [01:21<00:17,  3.62it/s] 83%|████████▎ | 289/350 [01:22<00:16,  3.70it/s] 83%|████████▎ | 290/350 [01:22<00:15,  3.77it/s] 83%|████████▎ | 291/350 [01:22<00:15,  3.81it/s] 83%|████████▎ | 292/350 [01:23<00:15,  3.80it/s] 84%|████████▎ | 293/350 [01:23<00:14,  3.83it/s] 84%|████████▍ | 294/350 [01:23<00:14,  3.86it/s] 84%|████████▍ | 295/350 [01:23<00:14,  3.87it/s] 85%|████████▍ | 296/350 [01:24<00:13,  3.88it/s] 85%|████████▍ | 297/350 [01:24<00:13,  3.89it/s] 85%|████████▌ | 298/350 [01:24<00:13,  3.90it/s] 85%|████████▌ | 299/350 [01:24<00:13,  3.91it/s] 86%|████████▌ | 300/350 [01:25<00:12,  3.90it/s] 86%|████████▌ | 301/350 [01:25<00:12,  3.90it/s] 86%|████████▋ | 302/350 [01:25<00:12,  3.90it/s] 87%|████████▋ | 303/350 [01:25<00:12,  3.91it/s] 87%|████████▋ | 304/350 [01:26<00:11,  3.90it/s] 87%|████████▋ | 305/350 [01:26<00:11,  3.91it/s] 87%|████████▋ | 306/350 [01:26<00:11,  3.91it/s] 88%|████████▊ | 307/350 [01:26<00:10,  3.91it/s] 88%|████████▊ | 308/350 [01:27<00:10,  3.91it/s] 88%|████████▊ | 309/350 [01:27<00:10,  3.92it/s] 89%|████████▊ | 310/350 [01:27<00:10,  3.91it/s] 89%|████████▉ | 311/350 [01:27<00:09,  3.91it/s] 89%|████████▉ | 312/350 [01:28<00:09,  3.91it/s] 89%|████████▉ | 313/350 [01:28<00:09,  3.90it/s] 90%|████████▉ | 314/350 [01:28<00:09,  3.90it/s] 90%|█████████ | 315/350 [01:28<00:07,  4.43it/s][INFO|trainer.py:540] 2022-04-17 21:27:30,304 >> The following columns in the evaluation set  don't have a corresponding argument in `RobertaPrefixForSequenceClassification.forward` and have been ignored: idx, span2_text, text, span1_index, span2_index, span1_text, span2_word_text.
[INFO|trainer.py:2243] 2022-04-17 21:27:30,306 >> ***** Running Evaluation *****
[INFO|trainer.py:2245] 2022-04-17 21:27:30,306 >>   Num examples = 104
[INFO|trainer.py:2248] 2022-04-17 21:27:30,306 >>   Batch size = 8

  0%|          | 0/13 [00:00<?, ?it/s][A
 23%|██▎       | 3/13 [00:00<00:00, 22.77it/s][A
 46%|████▌     | 6/13 [00:00<00:00, 17.59it/s][A
 62%|██████▏   | 8/13 [00:00<00:00, 16.65it/s][A
 77%|███████▋  | 10/13 [00:00<00:00, 16.12it/s][A
 92%|█████████▏| 12/13 [00:00<00:00, 15.83it/s][A                                                 
                                               [A 90%|█████████ | 315/350 [01:29<00:07,  4.43it/s]
100%|██████████| 13/13 [00:00<00:00, 15.83it/s][A
                                               [A                                                  90%|█████████ | 315/350 [01:29<00:07,  4.43it/s] 90%|█████████ | 316/350 [01:29<00:17,  2.00it/s] 91%|█████████ | 317/350 [01:30<00:14,  2.33it/s] 91%|█████████ | 318/350 [01:30<00:12,  2.66it/s] 91%|█████████ | 319/350 [01:30<00:10,  2.94it/s] 91%|█████████▏| 320/350 [01:30<00:09,  3.18it/s] 92%|█████████▏| 321/350 [01:31<00:08,  3.37it/s] 92%|█████████▏| 322/350 [01:31<00:07,  3.51it/s] 92%|█████████▏| 323/350 [01:31<00:07,  3.62it/s] 93%|█████████▎| 324/350 [01:31<00:07,  3.70it/s] 93%|█████████▎| 325/350 [01:32<00:06,  3.77it/s] 93%|█████████▎| 326/350 [01:32<00:06,  3.81it/s] 93%|█████████▎| 327/350 [01:32<00:05,  3.84it/s] 94%|█████████▎| 328/350 [01:32<00:05,  3.86it/s] 94%|█████████▍| 329/350 [01:33<00:05,  3.87it/s] 94%|█████████▍| 330/350 [01:33<00:05,  3.88it/s] 95%|█████████▍| 331/350 [01:33<00:04,  3.89it/s] 95%|█████████▍| 332/350 [01:34<00:04,  3.90it/s] 95%|█████████▌| 333/350 [01:34<00:04,  3.90it/s] 95%|█████████▌| 334/350 [01:34<00:04,  3.90it/s] 96%|█████████▌| 335/350 [01:34<00:03,  3.90it/s] 96%|█████████▌| 336/350 [01:35<00:03,  3.91it/s] 96%|█████████▋| 337/350 [01:35<00:03,  3.91it/s] 97%|█████████▋| 338/350 [01:35<00:03,  3.91it/s] 97%|█████████▋| 339/350 [01:35<00:02,  3.90it/s] 97%|█████████▋| 340/350 [01:36<00:02,  3.90it/s] 97%|█████████▋| 341/350 [01:36<00:02,  3.90it/s] 98%|█████████▊| 342/350 [01:36<00:02,  3.90it/s] 98%|█████████▊| 343/350 [01:36<00:01,  3.90it/s] 98%|█████████▊| 344/350 [01:37<00:01,  3.89it/s] 99%|█████████▊| 345/350 [01:37<00:01,  3.89it/s] 99%|█████████▉| 346/350 [01:37<00:01,  3.90it/s] 99%|█████████▉| 347/350 [01:37<00:00,  3.91it/s] 99%|█████████▉| 348/350 [01:38<00:00,  3.91it/s]100%|█████████▉| 349/350 [01:38<00:00,  3.91it/s]100%|██████████| 350/350 [01:38<00:00,  4.42it/s][INFO|trainer.py:540] 2022-04-17 21:27:40,055 >> The following columns in the evaluation set  don't have a corresponding argument in `RobertaPrefixForSequenceClassification.forward` and have been ignored: idx, span2_text, text, span1_index, span2_index, span1_text, span2_word_text.
[INFO|trainer.py:2243] 2022-04-17 21:27:40,057 >> ***** Running Evaluation *****
[INFO|trainer.py:2245] 2022-04-17 21:27:40,057 >>   Num examples = 104
[INFO|trainer.py:2248] 2022-04-17 21:27:40,057 >>   Batch size = 8

  0%|          | 0/13 [00:00<?, ?it/s][A
 23%|██▎       | 3/13 [00:00<00:00, 23.00it/s][A
 46%|████▌     | 6/13 [00:00<00:00, 17.62it/s][A
 62%|██████▏   | 8/13 [00:00<00:00, 16.70it/s][A
 77%|███████▋  | 10/13 [00:00<00:00, 16.13it/s][A
 92%|█████████▏| 12/13 [00:00<00:00, 15.77it/s][A                                                 
                                               [A100%|██████████| 350/350 [01:39<00:00,  4.42it/s]
100%|██████████| 13/13 [00:00<00:00, 15.77it/s][A
                                               [A                                                 100%|██████████| 350/350 [01:39<00:00,  4.42it/s][INFO|trainer.py:1409] 2022-04-17 21:27:40,946 >> 

Training completed. Do not forget to share your model on huggingface.co/models =)


                                                 100%|██████████| 350/350 [01:39<00:00,  4.42it/s]100%|██████████| 350/350 [01:39<00:00,  3.52it/s]
